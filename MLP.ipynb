{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM2Jo8OTMBskh4HnDnzQASa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Educat8n/AI-Development-Oxford/blob/main/MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining a simple neural network in TensorFlow 2.0\n",
        "\n",
        "* We use TensorFlow 2.0 to define a network that recognizes MNIST handwritten digits. \n",
        "* We start with a very simple neural network and then progressively improve it.\n",
        "* Load the dataset.\n",
        "```\n",
        "mnist = keras.datasets.mnist\n",
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
        "```\n",
        "* X_train is used for fine-tuning our net, and test sets, X_test, used for assessing the performance. \n",
        "* Data is converted into float32 to use 32-bit precision when training a neural network and normalized to the range [0,1]. \n",
        "```\n",
        "#normalize in [0,1]\n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
        "#X_train is 60000 rows of 28x28 values --> reshaped in 60000 x 784\n",
        "RESHAPED = 784\n",
        "#\n",
        "X_train = X_train.reshape(60000, RESHAPED)\n",
        "X_test = X_test.reshape(10000, RESHAPED)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "```\n",
        "* Perform a one-hot encoding on labels Y_train and Y_test.\n",
        "```\n",
        "# One-hot representation of the labels.\n",
        "Y_train = tf.keras.utils.to_categorical(Y_train, NB_CLASSES) Y_test = tf.keras.utils.to_categorical(Y_test, NB_CLASSES)\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dkfq7QeRnQsS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "mnist = keras.datasets.mnist\n",
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
        "print(X_train.shape, Y_train.shape, 'train samples')\n",
        "print(X_test.shape, Y_test.shape, 'test samples')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sl1G0tdOpHO0",
        "outputId": "86173cd0-0b41-485e-b553-35ee3e626922"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28) (60000,) train samples\n",
            "(10000, 28, 28) (10000,) test samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYiPq5ZM7eVG",
        "outputId": "e926e98e-35bd-4472-b8c9-4ce5c266519b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing mnist0.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile mnist0.py\n",
        "### MNIST Ver 0\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "\n",
        "# for reproducibility\n",
        "np.random.seed(1671)\n",
        "\n",
        "# network and training\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 128\n",
        "VERBOSE = 1\n",
        "NB_CLASSES = 10   # number of outputs = number of digits\n",
        "N_HIDDEN = 128\n",
        "VALIDATION_SPLIT=0.2 # how much TRAIN is reserved for VALIDATION\n",
        "\n",
        "# loading MNIST dataset\n",
        "# verify\n",
        "# the split between train and test is 60,000, and 10,000 respectly \n",
        "# one-hot is automatically applied\n",
        "mnist = keras.datasets.mnist\n",
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')\n",
        "\n",
        "\n",
        "#normalize in [0,1]\n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
        "#X_train is 60000 rows of 28x28 values --> reshaped in 60000 x 784\n",
        "RESHAPED = 784\n",
        "#\n",
        "X_train = X_train.reshape(60000, RESHAPED)\n",
        "X_test = X_test.reshape(10000, RESHAPED)\n",
        "print(Y_train[1])\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "# One-hot representation of the labels.\n",
        "Y_train = tf.keras.utils.to_categorical(Y_train, NB_CLASSES) \n",
        "Y_test = tf.keras.utils.to_categorical(Y_test, NB_CLASSES)\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(keras.layers.Dense(NB_CLASSES,\n",
        "   \t\tinput_shape=(RESHAPED,), kernel_initializer='zeros',\n",
        "   \t\tname='dense_layer', activation='softmax'))\n",
        "\n",
        "# summary of the model\n",
        "model.summary()\n",
        "\n",
        "# compiling the model\n",
        "model.compile(optimizer='SGD', \n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#training the moodel\n",
        "model.fit(X_train, Y_train,\n",
        "\t\tbatch_size=BATCH_SIZE, epochs=EPOCHS,\n",
        "\t\tverbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
        "\n",
        "#evalute the model\n",
        "test_loss, test_acc = model.evaluate(X_test, Y_test)\n",
        "print('Test accuracy:', test_acc)\n",
        "\n",
        "# making prediction\n",
        "#predictions = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%run mnist.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6DgOu_THETR",
        "outputId": "6248cfe8-0f9c-4790-856b-f6c720cc2556"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60000 train samples\n",
            "10000 test samples\n",
            "0\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_layer (Dense)         (None, 10)                7850      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,850\n",
            "Trainable params: 7,850\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.3528 - accuracy: 0.7773 - val_loss: 0.8784 - val_accuracy: 0.8440\n",
            "Epoch 2/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.7805 - accuracy: 0.8421 - val_loss: 0.6479 - val_accuracy: 0.8668\n",
            "Epoch 3/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.6351 - accuracy: 0.8576 - val_loss: 0.5549 - val_accuracy: 0.8752\n",
            "Epoch 4/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5646 - accuracy: 0.8661 - val_loss: 0.5037 - val_accuracy: 0.8799\n",
            "Epoch 5/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5216 - accuracy: 0.8723 - val_loss: 0.4702 - val_accuracy: 0.8852\n",
            "Epoch 6/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4921 - accuracy: 0.8768 - val_loss: 0.4466 - val_accuracy: 0.8892\n",
            "Epoch 7/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4702 - accuracy: 0.8802 - val_loss: 0.4289 - val_accuracy: 0.8928\n",
            "Epoch 8/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4533 - accuracy: 0.8828 - val_loss: 0.4150 - val_accuracy: 0.8946\n",
            "Epoch 9/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4396 - accuracy: 0.8847 - val_loss: 0.4038 - val_accuracy: 0.8962\n",
            "Epoch 10/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4282 - accuracy: 0.8874 - val_loss: 0.3943 - val_accuracy: 0.8985\n",
            "Epoch 11/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4187 - accuracy: 0.8889 - val_loss: 0.3864 - val_accuracy: 0.8995\n",
            "Epoch 12/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4104 - accuracy: 0.8906 - val_loss: 0.3797 - val_accuracy: 0.9003\n",
            "Epoch 13/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4032 - accuracy: 0.8923 - val_loss: 0.3737 - val_accuracy: 0.9020\n",
            "Epoch 14/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3968 - accuracy: 0.8936 - val_loss: 0.3684 - val_accuracy: 0.9023\n",
            "Epoch 15/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3912 - accuracy: 0.8944 - val_loss: 0.3636 - val_accuracy: 0.9038\n",
            "Epoch 16/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3861 - accuracy: 0.8956 - val_loss: 0.3596 - val_accuracy: 0.9045\n",
            "Epoch 17/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3815 - accuracy: 0.8962 - val_loss: 0.3557 - val_accuracy: 0.9049\n",
            "Epoch 18/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3773 - accuracy: 0.8973 - val_loss: 0.3523 - val_accuracy: 0.9056\n",
            "Epoch 19/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3735 - accuracy: 0.8980 - val_loss: 0.3490 - val_accuracy: 0.9068\n",
            "Epoch 20/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3699 - accuracy: 0.8986 - val_loss: 0.3462 - val_accuracy: 0.9062\n",
            "Epoch 21/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3666 - accuracy: 0.8995 - val_loss: 0.3435 - val_accuracy: 0.9078\n",
            "Epoch 22/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3636 - accuracy: 0.9003 - val_loss: 0.3410 - val_accuracy: 0.9082\n",
            "Epoch 23/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3608 - accuracy: 0.9006 - val_loss: 0.3387 - val_accuracy: 0.9086\n",
            "Epoch 24/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3581 - accuracy: 0.9013 - val_loss: 0.3366 - val_accuracy: 0.9089\n",
            "Epoch 25/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3556 - accuracy: 0.9019 - val_loss: 0.3344 - val_accuracy: 0.9096\n",
            "Epoch 26/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3533 - accuracy: 0.9027 - val_loss: 0.3325 - val_accuracy: 0.9096\n",
            "Epoch 27/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3511 - accuracy: 0.9029 - val_loss: 0.3308 - val_accuracy: 0.9098\n",
            "Epoch 28/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3490 - accuracy: 0.9033 - val_loss: 0.3290 - val_accuracy: 0.9108\n",
            "Epoch 29/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3470 - accuracy: 0.9038 - val_loss: 0.3274 - val_accuracy: 0.9112\n",
            "Epoch 30/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3451 - accuracy: 0.9043 - val_loss: 0.3259 - val_accuracy: 0.9118\n",
            "Epoch 31/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3433 - accuracy: 0.9049 - val_loss: 0.3244 - val_accuracy: 0.9118\n",
            "Epoch 32/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3416 - accuracy: 0.9051 - val_loss: 0.3231 - val_accuracy: 0.9120\n",
            "Epoch 33/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3400 - accuracy: 0.9057 - val_loss: 0.3217 - val_accuracy: 0.9122\n",
            "Epoch 34/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3384 - accuracy: 0.9065 - val_loss: 0.3205 - val_accuracy: 0.9123\n",
            "Epoch 35/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3369 - accuracy: 0.9067 - val_loss: 0.3193 - val_accuracy: 0.9129\n",
            "Epoch 36/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3355 - accuracy: 0.9070 - val_loss: 0.3182 - val_accuracy: 0.9133\n",
            "Epoch 37/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3341 - accuracy: 0.9073 - val_loss: 0.3171 - val_accuracy: 0.9133\n",
            "Epoch 38/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3328 - accuracy: 0.9075 - val_loss: 0.3160 - val_accuracy: 0.9136\n",
            "Epoch 39/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3316 - accuracy: 0.9076 - val_loss: 0.3150 - val_accuracy: 0.9138\n",
            "Epoch 40/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.3304 - accuracy: 0.9080 - val_loss: 0.3140 - val_accuracy: 0.9137\n",
            "Epoch 41/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3291 - accuracy: 0.9083 - val_loss: 0.3133 - val_accuracy: 0.9147\n",
            "Epoch 42/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3281 - accuracy: 0.9088 - val_loss: 0.3122 - val_accuracy: 0.9147\n",
            "Epoch 43/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3269 - accuracy: 0.9094 - val_loss: 0.3114 - val_accuracy: 0.9150\n",
            "Epoch 44/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3259 - accuracy: 0.9094 - val_loss: 0.3105 - val_accuracy: 0.9152\n",
            "Epoch 45/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3249 - accuracy: 0.9099 - val_loss: 0.3098 - val_accuracy: 0.9156\n",
            "Epoch 46/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3239 - accuracy: 0.9103 - val_loss: 0.3091 - val_accuracy: 0.9152\n",
            "Epoch 47/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3229 - accuracy: 0.9104 - val_loss: 0.3083 - val_accuracy: 0.9153\n",
            "Epoch 48/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3220 - accuracy: 0.9106 - val_loss: 0.3075 - val_accuracy: 0.9153\n",
            "Epoch 49/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3211 - accuracy: 0.9110 - val_loss: 0.3068 - val_accuracy: 0.9152\n",
            "Epoch 50/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3203 - accuracy: 0.9113 - val_loss: 0.3061 - val_accuracy: 0.9158\n",
            "Epoch 51/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3194 - accuracy: 0.9115 - val_loss: 0.3055 - val_accuracy: 0.9160\n",
            "Epoch 52/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3186 - accuracy: 0.9119 - val_loss: 0.3048 - val_accuracy: 0.9158\n",
            "Epoch 53/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3178 - accuracy: 0.9118 - val_loss: 0.3044 - val_accuracy: 0.9154\n",
            "Epoch 54/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3170 - accuracy: 0.9119 - val_loss: 0.3036 - val_accuracy: 0.9158\n",
            "Epoch 55/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3163 - accuracy: 0.9122 - val_loss: 0.3030 - val_accuracy: 0.9158\n",
            "Epoch 56/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3155 - accuracy: 0.9126 - val_loss: 0.3025 - val_accuracy: 0.9158\n",
            "Epoch 57/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3148 - accuracy: 0.9129 - val_loss: 0.3020 - val_accuracy: 0.9157\n",
            "Epoch 58/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3141 - accuracy: 0.9130 - val_loss: 0.3013 - val_accuracy: 0.9162\n",
            "Epoch 59/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3134 - accuracy: 0.9129 - val_loss: 0.3008 - val_accuracy: 0.9160\n",
            "Epoch 60/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3128 - accuracy: 0.9136 - val_loss: 0.3003 - val_accuracy: 0.9158\n",
            "Epoch 61/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3121 - accuracy: 0.9137 - val_loss: 0.2999 - val_accuracy: 0.9159\n",
            "Epoch 62/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.3115 - accuracy: 0.9137 - val_loss: 0.2993 - val_accuracy: 0.9158\n",
            "Epoch 63/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3108 - accuracy: 0.9141 - val_loss: 0.2989 - val_accuracy: 0.9162\n",
            "Epoch 64/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3103 - accuracy: 0.9141 - val_loss: 0.2984 - val_accuracy: 0.9166\n",
            "Epoch 65/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3096 - accuracy: 0.9146 - val_loss: 0.2981 - val_accuracy: 0.9170\n",
            "Epoch 66/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3091 - accuracy: 0.9144 - val_loss: 0.2976 - val_accuracy: 0.9171\n",
            "Epoch 67/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3085 - accuracy: 0.9146 - val_loss: 0.2971 - val_accuracy: 0.9169\n",
            "Epoch 68/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3079 - accuracy: 0.9149 - val_loss: 0.2968 - val_accuracy: 0.9169\n",
            "Epoch 69/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3074 - accuracy: 0.9152 - val_loss: 0.2963 - val_accuracy: 0.9172\n",
            "Epoch 70/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3069 - accuracy: 0.9152 - val_loss: 0.2959 - val_accuracy: 0.9174\n",
            "Epoch 71/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3063 - accuracy: 0.9154 - val_loss: 0.2955 - val_accuracy: 0.9173\n",
            "Epoch 72/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3059 - accuracy: 0.9154 - val_loss: 0.2952 - val_accuracy: 0.9170\n",
            "Epoch 73/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3054 - accuracy: 0.9159 - val_loss: 0.2948 - val_accuracy: 0.9178\n",
            "Epoch 74/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3049 - accuracy: 0.9159 - val_loss: 0.2945 - val_accuracy: 0.9175\n",
            "Epoch 75/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3044 - accuracy: 0.9161 - val_loss: 0.2941 - val_accuracy: 0.9175\n",
            "Epoch 76/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3039 - accuracy: 0.9161 - val_loss: 0.2937 - val_accuracy: 0.9178\n",
            "Epoch 77/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3034 - accuracy: 0.9159 - val_loss: 0.2934 - val_accuracy: 0.9180\n",
            "Epoch 78/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3030 - accuracy: 0.9160 - val_loss: 0.2931 - val_accuracy: 0.9182\n",
            "Epoch 79/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3025 - accuracy: 0.9164 - val_loss: 0.2928 - val_accuracy: 0.9181\n",
            "Epoch 80/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3021 - accuracy: 0.9163 - val_loss: 0.2924 - val_accuracy: 0.9183\n",
            "Epoch 81/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3017 - accuracy: 0.9164 - val_loss: 0.2921 - val_accuracy: 0.9184\n",
            "Epoch 82/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3013 - accuracy: 0.9165 - val_loss: 0.2918 - val_accuracy: 0.9183\n",
            "Epoch 83/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3009 - accuracy: 0.9166 - val_loss: 0.2915 - val_accuracy: 0.9187\n",
            "Epoch 84/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3005 - accuracy: 0.9165 - val_loss: 0.2912 - val_accuracy: 0.9188\n",
            "Epoch 85/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3000 - accuracy: 0.9168 - val_loss: 0.2909 - val_accuracy: 0.9187\n",
            "Epoch 86/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2996 - accuracy: 0.9170 - val_loss: 0.2906 - val_accuracy: 0.9191\n",
            "Epoch 87/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2993 - accuracy: 0.9172 - val_loss: 0.2903 - val_accuracy: 0.9195\n",
            "Epoch 88/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2989 - accuracy: 0.9171 - val_loss: 0.2901 - val_accuracy: 0.9187\n",
            "Epoch 89/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2985 - accuracy: 0.9171 - val_loss: 0.2899 - val_accuracy: 0.9194\n",
            "Epoch 90/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2982 - accuracy: 0.9175 - val_loss: 0.2895 - val_accuracy: 0.9188\n",
            "Epoch 91/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2978 - accuracy: 0.9175 - val_loss: 0.2892 - val_accuracy: 0.9193\n",
            "Epoch 92/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2974 - accuracy: 0.9175 - val_loss: 0.2891 - val_accuracy: 0.9191\n",
            "Epoch 93/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2971 - accuracy: 0.9176 - val_loss: 0.2887 - val_accuracy: 0.9197\n",
            "Epoch 94/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2967 - accuracy: 0.9178 - val_loss: 0.2885 - val_accuracy: 0.9192\n",
            "Epoch 95/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2964 - accuracy: 0.9176 - val_loss: 0.2883 - val_accuracy: 0.9197\n",
            "Epoch 96/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2961 - accuracy: 0.9177 - val_loss: 0.2880 - val_accuracy: 0.9195\n",
            "Epoch 97/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2957 - accuracy: 0.9178 - val_loss: 0.2878 - val_accuracy: 0.9202\n",
            "Epoch 98/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2954 - accuracy: 0.9179 - val_loss: 0.2876 - val_accuracy: 0.9203\n",
            "Epoch 99/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2951 - accuracy: 0.9181 - val_loss: 0.2874 - val_accuracy: 0.9199\n",
            "Epoch 100/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2948 - accuracy: 0.9183 - val_loss: 0.2872 - val_accuracy: 0.9200\n",
            "Epoch 101/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2945 - accuracy: 0.9180 - val_loss: 0.2869 - val_accuracy: 0.9207\n",
            "Epoch 102/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2942 - accuracy: 0.9183 - val_loss: 0.2867 - val_accuracy: 0.9204\n",
            "Epoch 103/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2939 - accuracy: 0.9185 - val_loss: 0.2865 - val_accuracy: 0.9203\n",
            "Epoch 104/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2935 - accuracy: 0.9184 - val_loss: 0.2864 - val_accuracy: 0.9201\n",
            "Epoch 105/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2933 - accuracy: 0.9186 - val_loss: 0.2861 - val_accuracy: 0.9202\n",
            "Epoch 106/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2930 - accuracy: 0.9187 - val_loss: 0.2858 - val_accuracy: 0.9206\n",
            "Epoch 107/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2927 - accuracy: 0.9189 - val_loss: 0.2857 - val_accuracy: 0.9204\n",
            "Epoch 108/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2924 - accuracy: 0.9190 - val_loss: 0.2854 - val_accuracy: 0.9203\n",
            "Epoch 109/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2921 - accuracy: 0.9193 - val_loss: 0.2853 - val_accuracy: 0.9209\n",
            "Epoch 110/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2919 - accuracy: 0.9189 - val_loss: 0.2851 - val_accuracy: 0.9204\n",
            "Epoch 111/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2916 - accuracy: 0.9189 - val_loss: 0.2849 - val_accuracy: 0.9208\n",
            "Epoch 112/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2913 - accuracy: 0.9191 - val_loss: 0.2848 - val_accuracy: 0.9208\n",
            "Epoch 113/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2910 - accuracy: 0.9196 - val_loss: 0.2847 - val_accuracy: 0.9208\n",
            "Epoch 114/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2908 - accuracy: 0.9192 - val_loss: 0.2843 - val_accuracy: 0.9208\n",
            "Epoch 115/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2905 - accuracy: 0.9195 - val_loss: 0.2842 - val_accuracy: 0.9208\n",
            "Epoch 116/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2903 - accuracy: 0.9193 - val_loss: 0.2840 - val_accuracy: 0.9210\n",
            "Epoch 117/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2900 - accuracy: 0.9193 - val_loss: 0.2839 - val_accuracy: 0.9211\n",
            "Epoch 118/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2897 - accuracy: 0.9194 - val_loss: 0.2836 - val_accuracy: 0.9212\n",
            "Epoch 119/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2895 - accuracy: 0.9198 - val_loss: 0.2835 - val_accuracy: 0.9205\n",
            "Epoch 120/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2893 - accuracy: 0.9195 - val_loss: 0.2833 - val_accuracy: 0.9208\n",
            "Epoch 121/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2890 - accuracy: 0.9198 - val_loss: 0.2832 - val_accuracy: 0.9212\n",
            "Epoch 122/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2888 - accuracy: 0.9196 - val_loss: 0.2830 - val_accuracy: 0.9212\n",
            "Epoch 123/200\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.2886 - accuracy: 0.9197 - val_loss: 0.2829 - val_accuracy: 0.9211\n",
            "Epoch 124/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2883 - accuracy: 0.9199 - val_loss: 0.2827 - val_accuracy: 0.9208\n",
            "Epoch 125/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2881 - accuracy: 0.9200 - val_loss: 0.2826 - val_accuracy: 0.9211\n",
            "Epoch 126/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2878 - accuracy: 0.9198 - val_loss: 0.2825 - val_accuracy: 0.9218\n",
            "Epoch 127/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2876 - accuracy: 0.9201 - val_loss: 0.2823 - val_accuracy: 0.9212\n",
            "Epoch 128/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2874 - accuracy: 0.9202 - val_loss: 0.2821 - val_accuracy: 0.9214\n",
            "Epoch 129/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2872 - accuracy: 0.9203 - val_loss: 0.2820 - val_accuracy: 0.9210\n",
            "Epoch 130/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2870 - accuracy: 0.9204 - val_loss: 0.2818 - val_accuracy: 0.9213\n",
            "Epoch 131/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2868 - accuracy: 0.9204 - val_loss: 0.2817 - val_accuracy: 0.9213\n",
            "Epoch 132/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2866 - accuracy: 0.9203 - val_loss: 0.2815 - val_accuracy: 0.9210\n",
            "Epoch 133/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2863 - accuracy: 0.9204 - val_loss: 0.2814 - val_accuracy: 0.9210\n",
            "Epoch 134/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2861 - accuracy: 0.9204 - val_loss: 0.2812 - val_accuracy: 0.9216\n",
            "Epoch 135/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2859 - accuracy: 0.9204 - val_loss: 0.2812 - val_accuracy: 0.9220\n",
            "Epoch 136/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2857 - accuracy: 0.9203 - val_loss: 0.2810 - val_accuracy: 0.9217\n",
            "Epoch 137/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2855 - accuracy: 0.9208 - val_loss: 0.2809 - val_accuracy: 0.9216\n",
            "Epoch 138/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2853 - accuracy: 0.9208 - val_loss: 0.2808 - val_accuracy: 0.9214\n",
            "Epoch 139/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2851 - accuracy: 0.9208 - val_loss: 0.2807 - val_accuracy: 0.9213\n",
            "Epoch 140/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2849 - accuracy: 0.9209 - val_loss: 0.2805 - val_accuracy: 0.9218\n",
            "Epoch 141/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2847 - accuracy: 0.9207 - val_loss: 0.2804 - val_accuracy: 0.9216\n",
            "Epoch 142/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2845 - accuracy: 0.9207 - val_loss: 0.2802 - val_accuracy: 0.9218\n",
            "Epoch 143/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2843 - accuracy: 0.9210 - val_loss: 0.2801 - val_accuracy: 0.9218\n",
            "Epoch 144/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2841 - accuracy: 0.9208 - val_loss: 0.2800 - val_accuracy: 0.9216\n",
            "Epoch 145/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2840 - accuracy: 0.9210 - val_loss: 0.2799 - val_accuracy: 0.9218\n",
            "Epoch 146/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2838 - accuracy: 0.9210 - val_loss: 0.2798 - val_accuracy: 0.9216\n",
            "Epoch 147/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2836 - accuracy: 0.9211 - val_loss: 0.2797 - val_accuracy: 0.9218\n",
            "Epoch 148/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2834 - accuracy: 0.9210 - val_loss: 0.2795 - val_accuracy: 0.9219\n",
            "Epoch 149/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2832 - accuracy: 0.9212 - val_loss: 0.2794 - val_accuracy: 0.9220\n",
            "Epoch 150/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2830 - accuracy: 0.9210 - val_loss: 0.2793 - val_accuracy: 0.9218\n",
            "Epoch 151/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2829 - accuracy: 0.9211 - val_loss: 0.2792 - val_accuracy: 0.9220\n",
            "Epoch 152/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2827 - accuracy: 0.9214 - val_loss: 0.2792 - val_accuracy: 0.9221\n",
            "Epoch 153/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2825 - accuracy: 0.9213 - val_loss: 0.2789 - val_accuracy: 0.9222\n",
            "Epoch 154/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2824 - accuracy: 0.9214 - val_loss: 0.2789 - val_accuracy: 0.9220\n",
            "Epoch 155/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2822 - accuracy: 0.9215 - val_loss: 0.2787 - val_accuracy: 0.9221\n",
            "Epoch 156/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2820 - accuracy: 0.9215 - val_loss: 0.2786 - val_accuracy: 0.9222\n",
            "Epoch 157/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2819 - accuracy: 0.9217 - val_loss: 0.2785 - val_accuracy: 0.9220\n",
            "Epoch 158/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2817 - accuracy: 0.9215 - val_loss: 0.2784 - val_accuracy: 0.9220\n",
            "Epoch 159/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2815 - accuracy: 0.9215 - val_loss: 0.2785 - val_accuracy: 0.9219\n",
            "Epoch 160/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2814 - accuracy: 0.9216 - val_loss: 0.2782 - val_accuracy: 0.9223\n",
            "Epoch 161/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2812 - accuracy: 0.9218 - val_loss: 0.2782 - val_accuracy: 0.9223\n",
            "Epoch 162/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2811 - accuracy: 0.9217 - val_loss: 0.2780 - val_accuracy: 0.9224\n",
            "Epoch 163/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2809 - accuracy: 0.9216 - val_loss: 0.2779 - val_accuracy: 0.9221\n",
            "Epoch 164/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2807 - accuracy: 0.9217 - val_loss: 0.2778 - val_accuracy: 0.9223\n",
            "Epoch 165/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2806 - accuracy: 0.9217 - val_loss: 0.2778 - val_accuracy: 0.9224\n",
            "Epoch 166/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2804 - accuracy: 0.9219 - val_loss: 0.2776 - val_accuracy: 0.9227\n",
            "Epoch 167/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2802 - accuracy: 0.9219 - val_loss: 0.2776 - val_accuracy: 0.9224\n",
            "Epoch 168/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2801 - accuracy: 0.9220 - val_loss: 0.2774 - val_accuracy: 0.9224\n",
            "Epoch 169/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2799 - accuracy: 0.9219 - val_loss: 0.2773 - val_accuracy: 0.9232\n",
            "Epoch 170/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2798 - accuracy: 0.9218 - val_loss: 0.2773 - val_accuracy: 0.9228\n",
            "Epoch 171/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2797 - accuracy: 0.9221 - val_loss: 0.2772 - val_accuracy: 0.9229\n",
            "Epoch 172/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2795 - accuracy: 0.9222 - val_loss: 0.2771 - val_accuracy: 0.9226\n",
            "Epoch 173/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2793 - accuracy: 0.9221 - val_loss: 0.2771 - val_accuracy: 0.9229\n",
            "Epoch 174/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2792 - accuracy: 0.9219 - val_loss: 0.2770 - val_accuracy: 0.9230\n",
            "Epoch 175/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2791 - accuracy: 0.9222 - val_loss: 0.2768 - val_accuracy: 0.9229\n",
            "Epoch 176/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2789 - accuracy: 0.9223 - val_loss: 0.2767 - val_accuracy: 0.9229\n",
            "Epoch 177/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2788 - accuracy: 0.9223 - val_loss: 0.2767 - val_accuracy: 0.9232\n",
            "Epoch 178/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2786 - accuracy: 0.9222 - val_loss: 0.2766 - val_accuracy: 0.9228\n",
            "Epoch 179/200\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2785 - accuracy: 0.9222 - val_loss: 0.2765 - val_accuracy: 0.9233\n",
            "Epoch 180/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2783 - accuracy: 0.9223 - val_loss: 0.2765 - val_accuracy: 0.9229\n",
            "Epoch 181/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2782 - accuracy: 0.9224 - val_loss: 0.2764 - val_accuracy: 0.9231\n",
            "Epoch 182/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2781 - accuracy: 0.9224 - val_loss: 0.2762 - val_accuracy: 0.9229\n",
            "Epoch 183/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2780 - accuracy: 0.9223 - val_loss: 0.2762 - val_accuracy: 0.9232\n",
            "Epoch 184/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2778 - accuracy: 0.9225 - val_loss: 0.2762 - val_accuracy: 0.9223\n",
            "Epoch 185/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2776 - accuracy: 0.9226 - val_loss: 0.2760 - val_accuracy: 0.9231\n",
            "Epoch 186/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2776 - accuracy: 0.9225 - val_loss: 0.2759 - val_accuracy: 0.9233\n",
            "Epoch 187/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2774 - accuracy: 0.9226 - val_loss: 0.2759 - val_accuracy: 0.9227\n",
            "Epoch 188/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2773 - accuracy: 0.9225 - val_loss: 0.2758 - val_accuracy: 0.9230\n",
            "Epoch 189/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2772 - accuracy: 0.9225 - val_loss: 0.2757 - val_accuracy: 0.9233\n",
            "Epoch 190/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2770 - accuracy: 0.9228 - val_loss: 0.2758 - val_accuracy: 0.9233\n",
            "Epoch 191/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2769 - accuracy: 0.9226 - val_loss: 0.2755 - val_accuracy: 0.9234\n",
            "Epoch 192/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2768 - accuracy: 0.9226 - val_loss: 0.2755 - val_accuracy: 0.9233\n",
            "Epoch 193/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2766 - accuracy: 0.9229 - val_loss: 0.2756 - val_accuracy: 0.9233\n",
            "Epoch 194/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2765 - accuracy: 0.9229 - val_loss: 0.2753 - val_accuracy: 0.9235\n",
            "Epoch 195/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2764 - accuracy: 0.9230 - val_loss: 0.2753 - val_accuracy: 0.9234\n",
            "Epoch 196/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2763 - accuracy: 0.9225 - val_loss: 0.2752 - val_accuracy: 0.9232\n",
            "Epoch 197/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2762 - accuracy: 0.9229 - val_loss: 0.2751 - val_accuracy: 0.9235\n",
            "Epoch 198/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2760 - accuracy: 0.9232 - val_loss: 0.2752 - val_accuracy: 0.9233\n",
            "Epoch 199/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2759 - accuracy: 0.9228 - val_loss: 0.2750 - val_accuracy: 0.9236\n",
            "Epoch 200/200\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2758 - accuracy: 0.9231 - val_loss: 0.2749 - val_accuracy: 0.9237\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.2769 - accuracy: 0.9222\n",
            "Test accuracy: 0.9222000241279602\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Improving Model Performance- Hyperparameter Tuning\n",
        "\n",
        "* Model Architecture\n",
        "  * Change Number of hidden layers\n",
        "  * Change number of hidden units/neurons\n",
        "\n",
        "\n",
        "* Epochs\n",
        "* Batch-Size\n",
        "```\n",
        "model.fit(X_train, Y_train,\n",
        "\t\tbatch_size=BATCH_SIZE, epochs=EPOCHS,\n",
        "\t\tverbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
        "    ```\n",
        "\n",
        "* Optimizer\n",
        " * SGD\n",
        " * Adam\n",
        " * Adadelta\n",
        "```\n",
        "model.compile(optimizer='SGD',\n",
        "                 loss='categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "```\n",
        "* Learning Rate\n",
        "```\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "OPTMIZER = SGD(lr=0.001)\n",
        ":\n",
        ":\n",
        ":\n",
        "# compiling the model\n",
        "model.compile(optimizer=OPTMIZER, \n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "```\n",
        "\n",
        "* Regularization\n",
        " * L1/L2\n",
        " * Dropout Layer\n",
        " * Batchnormalization Layer\n"
      ],
      "metadata": {
        "id": "NnFF74DVuGHA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Change Number of hidden layers.\n",
        "```\n",
        "# Build the model.\n",
        "model = tf.keras.models.Sequential() \n",
        "model.add(keras.layers.Dense(N_HIDDEN,\n",
        "             input_shape=(RESHAPED,),name='dense_layer', activation='relu')) \n",
        "model.add(keras.layers.Dense(N_HIDDEN,name='dense_layer_2', activation='relu')) \n",
        "model.add(keras.layers.Dense(NB_CLASSES,name='dense_layer_3', activation='softmax'))\n",
        "# Summary of the model. \n",
        "model.summary()\n",
        "```\n"
      ],
      "metadata": {
        "id": "iV4qGBbhsFRl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile mnist1.py\n",
        "### MNIST Ver 1\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "\n",
        "# for reproducibility\n",
        "np.random.seed(1671)\n",
        "\n",
        "# network and training\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 128\n",
        "VERBOSE = 1\n",
        "NB_CLASSES = 10   # number of outputs = number of digits\n",
        "N_HIDDEN = 128\n",
        "VALIDATION_SPLIT=0.2 # how much TRAIN is reserved for VALIDATION\n",
        "\n",
        "# loading MNIST dataset\n",
        "# verify\n",
        "# the split between train and test is 60,000, and 10,000 respectly \n",
        "# one-hot is automatically applied\n",
        "mnist = keras.datasets.mnist\n",
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')\n",
        "\n",
        "\n",
        "#normalize in [0,1]\n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
        "#X_train is 60000 rows of 28x28 values --> reshaped in 60000 x 784\n",
        "RESHAPED = 784\n",
        "#\n",
        "X_train = X_train.reshape(60000, RESHAPED)\n",
        "X_test = X_test.reshape(10000, RESHAPED)\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "# One-hot representation of the labels.\n",
        "Y_train = tf.keras.utils.to_categorical(Y_train, NB_CLASSES) \n",
        "Y_test = tf.keras.utils.to_categorical(Y_test, NB_CLASSES)\n",
        "\n",
        "model = tf.keras.models.Sequential() \n",
        "model.add(keras.layers.Dense(N_HIDDEN,\n",
        "             input_shape=(RESHAPED,),name='dense_layer_1', activation='relu')) \n",
        "model.add(keras.layers.Dense(N_HIDDEN,name='dense_layer_2', activation='relu')) \n",
        "model.add(keras.layers.Dense(NB_CLASSES,name='dense_layer_3', activation='softmax'))\n",
        "\n",
        "# summary of the model\n",
        "model.summary()\n",
        "\n",
        "# compiling the model\n",
        "model.compile(optimizer='SGD', \n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#training the moodel\n",
        "model.fit(X_train, Y_train,\n",
        "\t\tbatch_size=BATCH_SIZE, epochs=EPOCHS,\n",
        "\t\tverbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
        "\n",
        "#evalute the model\n",
        "test_loss, test_acc = model.evaluate(X_test, Y_test)\n",
        "print('Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EaKEj7e3sEel",
        "outputId": "c208ec72-9c43-43fd-c635-6096880e19f4"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting mnist1.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%run mnist1.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCypoPkhHGYz",
        "outputId": "6935ef7f-a95e-473f-d218-2a6da18c6476"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60000 train samples\n",
            "10000 test samples\n",
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_layer_1 (Dense)       (None, 128)               100480    \n",
            "                                                                 \n",
            " dense_layer_2 (Dense)       (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_layer_3 (Dense)       (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 118,282\n",
            "Trainable params: 118,282\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 3s 6ms/step - loss: 1.4628 - accuracy: 0.6289 - val_loss: 0.7386 - val_accuracy: 0.8337\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.5906 - accuracy: 0.8509 - val_loss: 0.4514 - val_accuracy: 0.8820\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4333 - accuracy: 0.8814 - val_loss: 0.3692 - val_accuracy: 0.8986\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.3745 - accuracy: 0.8947 - val_loss: 0.3329 - val_accuracy: 0.9065\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.3417 - accuracy: 0.9023 - val_loss: 0.3085 - val_accuracy: 0.9115\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.3192 - accuracy: 0.9082 - val_loss: 0.2936 - val_accuracy: 0.9153\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.3021 - accuracy: 0.9135 - val_loss: 0.2773 - val_accuracy: 0.9202\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2878 - accuracy: 0.9181 - val_loss: 0.2654 - val_accuracy: 0.9225\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2757 - accuracy: 0.9214 - val_loss: 0.2554 - val_accuracy: 0.9247\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2649 - accuracy: 0.9241 - val_loss: 0.2475 - val_accuracy: 0.9281\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2552 - accuracy: 0.9269 - val_loss: 0.2417 - val_accuracy: 0.9292\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.2465 - accuracy: 0.9299 - val_loss: 0.2324 - val_accuracy: 0.9321\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.2383 - accuracy: 0.9329 - val_loss: 0.2258 - val_accuracy: 0.9348\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2308 - accuracy: 0.9350 - val_loss: 0.2191 - val_accuracy: 0.9358\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2237 - accuracy: 0.9365 - val_loss: 0.2141 - val_accuracy: 0.9393\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2172 - accuracy: 0.9389 - val_loss: 0.2078 - val_accuracy: 0.9409\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2104 - accuracy: 0.9399 - val_loss: 0.2030 - val_accuracy: 0.9421\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2046 - accuracy: 0.9421 - val_loss: 0.1987 - val_accuracy: 0.9435\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1988 - accuracy: 0.9437 - val_loss: 0.1936 - val_accuracy: 0.9452\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1934 - accuracy: 0.9449 - val_loss: 0.1894 - val_accuracy: 0.9469\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1884 - accuracy: 0.9465 - val_loss: 0.1863 - val_accuracy: 0.9476\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1837 - accuracy: 0.9476 - val_loss: 0.1812 - val_accuracy: 0.9483\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1788 - accuracy: 0.9490 - val_loss: 0.1778 - val_accuracy: 0.9492\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1746 - accuracy: 0.9499 - val_loss: 0.1750 - val_accuracy: 0.9505\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1702 - accuracy: 0.9515 - val_loss: 0.1711 - val_accuracy: 0.9515\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.1661 - accuracy: 0.9525 - val_loss: 0.1680 - val_accuracy: 0.9522\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1623 - accuracy: 0.9534 - val_loss: 0.1658 - val_accuracy: 0.9520\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1587 - accuracy: 0.9547 - val_loss: 0.1616 - val_accuracy: 0.9545\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1550 - accuracy: 0.9558 - val_loss: 0.1593 - val_accuracy: 0.9545\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1516 - accuracy: 0.9567 - val_loss: 0.1580 - val_accuracy: 0.9552\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.1484 - accuracy: 0.9576 - val_loss: 0.1546 - val_accuracy: 0.9563\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1451 - accuracy: 0.9585 - val_loss: 0.1526 - val_accuracy: 0.9574\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1421 - accuracy: 0.9589 - val_loss: 0.1498 - val_accuracy: 0.9577\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1392 - accuracy: 0.9605 - val_loss: 0.1480 - val_accuracy: 0.9579\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1362 - accuracy: 0.9612 - val_loss: 0.1463 - val_accuracy: 0.9594\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1335 - accuracy: 0.9625 - val_loss: 0.1438 - val_accuracy: 0.9597\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1309 - accuracy: 0.9628 - val_loss: 0.1424 - val_accuracy: 0.9604\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1283 - accuracy: 0.9635 - val_loss: 0.1404 - val_accuracy: 0.9611\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1258 - accuracy: 0.9648 - val_loss: 0.1391 - val_accuracy: 0.9615\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1233 - accuracy: 0.9650 - val_loss: 0.1374 - val_accuracy: 0.9607\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1211 - accuracy: 0.9660 - val_loss: 0.1352 - val_accuracy: 0.9621\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1188 - accuracy: 0.9663 - val_loss: 0.1339 - val_accuracy: 0.9618\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1166 - accuracy: 0.9677 - val_loss: 0.1322 - val_accuracy: 0.9626\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1143 - accuracy: 0.9677 - val_loss: 0.1319 - val_accuracy: 0.9623\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.1124 - accuracy: 0.9687 - val_loss: 0.1290 - val_accuracy: 0.9628\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1103 - accuracy: 0.9693 - val_loss: 0.1284 - val_accuracy: 0.9633\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1081 - accuracy: 0.9700 - val_loss: 0.1271 - val_accuracy: 0.9644\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1066 - accuracy: 0.9703 - val_loss: 0.1258 - val_accuracy: 0.9647\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1045 - accuracy: 0.9703 - val_loss: 0.1253 - val_accuracy: 0.9643\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1028 - accuracy: 0.9717 - val_loss: 0.1235 - val_accuracy: 0.9653\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1179 - accuracy: 0.9650\n",
            "Test accuracy: 0.9649999737739563\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Change number of hidden units\n",
        "\n",
        "```\n",
        "N_HIDDEN = 64\n",
        ":\n",
        ":\n",
        "# Build the model.\n",
        "model = tf.keras.models.Sequential() \n",
        "model.add(keras.layers.Dense(N_HIDDEN,\n",
        "             input_shape=(RESHAPED,),name='dense_layer', activation='relu')) \n",
        "model.add(keras.layers.Dense(N_HIDDEN,name='dense_layer_2', activation='relu')) \n",
        "model.add(keras.layers.Dense(NB_CLASSES,name='dense_layer_3', activation='softmax'))\n",
        "# Summary of the model. \n",
        "model.summary()\n",
        "```\n"
      ],
      "metadata": {
        "id": "hCVprsAOyKHv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile mnist2.py\n",
        "### MNIST Ver 2\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "\n",
        "# for reproducibility\n",
        "np.random.seed(1671)\n",
        "\n",
        "# network and training\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 128\n",
        "VERBOSE = 1\n",
        "NB_CLASSES = 10   # number of outputs = number of digits\n",
        "N_HIDDEN = 64\n",
        "VALIDATION_SPLIT=0.2 # how much TRAIN is reserved for VALIDATION\n",
        "\n",
        "# loading MNIST dataset\n",
        "# verify\n",
        "# the split between train and test is 60,000, and 10,000 respectly \n",
        "# one-hot is automatically applied\n",
        "mnist = keras.datasets.mnist\n",
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')\n",
        "\n",
        "\n",
        "#normalize in [0,1]\n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
        "#X_train is 60000 rows of 28x28 values --> reshaped in 60000 x 784\n",
        "RESHAPED = 784\n",
        "#\n",
        "X_train = X_train.reshape(60000, RESHAPED)\n",
        "X_test = X_test.reshape(10000, RESHAPED)\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "# One-hot representation of the labels.\n",
        "Y_train = tf.keras.utils.to_categorical(Y_train, NB_CLASSES) \n",
        "Y_test = tf.keras.utils.to_categorical(Y_test, NB_CLASSES)\n",
        "\n",
        "model = tf.keras.models.Sequential() \n",
        "model.add(keras.layers.Dense(N_HIDDEN,\n",
        "             input_shape=(RESHAPED,),name='dense_layer_1', activation='relu')) \n",
        "model.add(keras.layers.Dense(N_HIDDEN,name='dense_layer_2', activation='relu')) \n",
        "model.add(keras.layers.Dense(NB_CLASSES,name='dense_layer_3', activation='softmax'))\n",
        "\n",
        "# summary of the model\n",
        "model.summary()\n",
        "\n",
        "# compiling the model\n",
        "model.compile(optimizer='SGD', \n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#training the moodel\n",
        "model.fit(X_train, Y_train,\n",
        "\t\tbatch_size=BATCH_SIZE, epochs=EPOCHS,\n",
        "\t\tverbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
        "\n",
        "#evalute the model\n",
        "test_loss, test_acc = model.evaluate(X_test, Y_test)\n",
        "print('Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tmf-iZVhyZdB",
        "outputId": "f432065a-f1d4-461d-8017-273e28eafbfc"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting mnist2.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%run mnist2.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69NZlbCNyryA",
        "outputId": "cd7022d5-8b3d-4e2f-a414-c451c14c3542"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60000 train samples\n",
            "10000 test samples\n",
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_layer_1 (Dense)       (None, 64)                50240     \n",
            "                                                                 \n",
            " dense_layer_2 (Dense)       (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_layer_3 (Dense)       (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 55,050\n",
            "Trainable params: 55,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 3s 6ms/step - loss: 1.5052 - accuracy: 0.6035 - val_loss: 0.7940 - val_accuracy: 0.8262\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6256 - accuracy: 0.8454 - val_loss: 0.4738 - val_accuracy: 0.8801\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4557 - accuracy: 0.8769 - val_loss: 0.3895 - val_accuracy: 0.8924\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3930 - accuracy: 0.8905 - val_loss: 0.3483 - val_accuracy: 0.9027\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3591 - accuracy: 0.8983 - val_loss: 0.3254 - val_accuracy: 0.9074\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3363 - accuracy: 0.9040 - val_loss: 0.3077 - val_accuracy: 0.9114\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3191 - accuracy: 0.9094 - val_loss: 0.2932 - val_accuracy: 0.9166\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3054 - accuracy: 0.9129 - val_loss: 0.2836 - val_accuracy: 0.9193\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2933 - accuracy: 0.9158 - val_loss: 0.2733 - val_accuracy: 0.9231\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2829 - accuracy: 0.9190 - val_loss: 0.2647 - val_accuracy: 0.9248\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2735 - accuracy: 0.9221 - val_loss: 0.2578 - val_accuracy: 0.9268\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2650 - accuracy: 0.9239 - val_loss: 0.2514 - val_accuracy: 0.9283\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2570 - accuracy: 0.9266 - val_loss: 0.2441 - val_accuracy: 0.9318\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2496 - accuracy: 0.9288 - val_loss: 0.2373 - val_accuracy: 0.9339\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2428 - accuracy: 0.9309 - val_loss: 0.2321 - val_accuracy: 0.9354\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2363 - accuracy: 0.9328 - val_loss: 0.2270 - val_accuracy: 0.9361\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2303 - accuracy: 0.9346 - val_loss: 0.2214 - val_accuracy: 0.9378\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2241 - accuracy: 0.9362 - val_loss: 0.2171 - val_accuracy: 0.9391\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2187 - accuracy: 0.9380 - val_loss: 0.2127 - val_accuracy: 0.9416\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2136 - accuracy: 0.9394 - val_loss: 0.2087 - val_accuracy: 0.9413\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2083 - accuracy: 0.9406 - val_loss: 0.2043 - val_accuracy: 0.9437\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2034 - accuracy: 0.9424 - val_loss: 0.2006 - val_accuracy: 0.9436\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1991 - accuracy: 0.9429 - val_loss: 0.1968 - val_accuracy: 0.9461\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1945 - accuracy: 0.9445 - val_loss: 0.1934 - val_accuracy: 0.9458\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1905 - accuracy: 0.9456 - val_loss: 0.1896 - val_accuracy: 0.9473\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1864 - accuracy: 0.9467 - val_loss: 0.1865 - val_accuracy: 0.9484\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1823 - accuracy: 0.9476 - val_loss: 0.1830 - val_accuracy: 0.9489\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1784 - accuracy: 0.9482 - val_loss: 0.1806 - val_accuracy: 0.9492\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1747 - accuracy: 0.9499 - val_loss: 0.1778 - val_accuracy: 0.9506\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1713 - accuracy: 0.9505 - val_loss: 0.1741 - val_accuracy: 0.9514\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1676 - accuracy: 0.9517 - val_loss: 0.1720 - val_accuracy: 0.9519\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1645 - accuracy: 0.9528 - val_loss: 0.1693 - val_accuracy: 0.9529\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1614 - accuracy: 0.9538 - val_loss: 0.1662 - val_accuracy: 0.9536\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1584 - accuracy: 0.9546 - val_loss: 0.1643 - val_accuracy: 0.9542\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1554 - accuracy: 0.9555 - val_loss: 0.1623 - val_accuracy: 0.9545\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1523 - accuracy: 0.9562 - val_loss: 0.1597 - val_accuracy: 0.9543\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1495 - accuracy: 0.9574 - val_loss: 0.1588 - val_accuracy: 0.9555\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1466 - accuracy: 0.9581 - val_loss: 0.1551 - val_accuracy: 0.9564\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1441 - accuracy: 0.9585 - val_loss: 0.1544 - val_accuracy: 0.9557\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1414 - accuracy: 0.9595 - val_loss: 0.1531 - val_accuracy: 0.9572\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1391 - accuracy: 0.9605 - val_loss: 0.1508 - val_accuracy: 0.9572\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1367 - accuracy: 0.9613 - val_loss: 0.1487 - val_accuracy: 0.9582\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1341 - accuracy: 0.9617 - val_loss: 0.1483 - val_accuracy: 0.9582\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1320 - accuracy: 0.9624 - val_loss: 0.1458 - val_accuracy: 0.9586\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1299 - accuracy: 0.9636 - val_loss: 0.1441 - val_accuracy: 0.9588\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1276 - accuracy: 0.9640 - val_loss: 0.1426 - val_accuracy: 0.9603\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1255 - accuracy: 0.9647 - val_loss: 0.1417 - val_accuracy: 0.9600\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1236 - accuracy: 0.9650 - val_loss: 0.1389 - val_accuracy: 0.9611\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1215 - accuracy: 0.9656 - val_loss: 0.1378 - val_accuracy: 0.9611\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1197 - accuracy: 0.9658 - val_loss: 0.1380 - val_accuracy: 0.9617\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1326 - accuracy: 0.9598\n",
            "Test accuracy: 0.9598000049591064\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Change Model Fit Parameters\n",
        "* Change Epochs\n",
        "* Change Batch Size\n",
        "```\n",
        "# network and training\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 128\n",
        "```\n"
      ],
      "metadata": {
        "id": "NhB4NhIy0tEa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile mnist3.py\n",
        "### MNIST Ver 3\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "\n",
        "# for reproducibility\n",
        "np.random.seed(1671)\n",
        "\n",
        "# network and training\n",
        "EPOCHS = 75\n",
        "BATCH_SIZE = 128\n",
        "VERBOSE = 1\n",
        "NB_CLASSES = 10   # number of outputs = number of digits\n",
        "N_HIDDEN = 64\n",
        "VALIDATION_SPLIT=0.2 # how much TRAIN is reserved for VALIDATION\n",
        "\n",
        "# loading MNIST dataset\n",
        "# verify\n",
        "# the split between train and test is 60,000, and 10,000 respectly \n",
        "# one-hot is automatically applied\n",
        "mnist = keras.datasets.mnist\n",
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')\n",
        "\n",
        "\n",
        "#normalize in [0,1]\n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
        "#X_train is 60000 rows of 28x28 values --> reshaped in 60000 x 784\n",
        "RESHAPED = 784\n",
        "#\n",
        "X_train = X_train.reshape(60000, RESHAPED)\n",
        "X_test = X_test.reshape(10000, RESHAPED)\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "# One-hot representation of the labels.\n",
        "Y_train = tf.keras.utils.to_categorical(Y_train, NB_CLASSES) \n",
        "Y_test = tf.keras.utils.to_categorical(Y_test, NB_CLASSES)\n",
        "\n",
        "model = tf.keras.models.Sequential() \n",
        "model.add(keras.layers.Dense(N_HIDDEN,\n",
        "             input_shape=(RESHAPED,),name='dense_layer_1', activation='relu')) \n",
        "model.add(keras.layers.Dense(N_HIDDEN,name='dense_layer_2', activation='relu')) \n",
        "model.add(keras.layers.Dense(NB_CLASSES,name='dense_layer_3', activation='softmax'))\n",
        "\n",
        "# summary of the model\n",
        "model.summary()\n",
        "\n",
        "# compiling the model\n",
        "model.compile(optimizer='SGD', \n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#training the moodel\n",
        "model.fit(X_train, Y_train,\n",
        "\t\tbatch_size=BATCH_SIZE, epochs=EPOCHS,\n",
        "\t\tverbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
        "\n",
        "#evalute the model\n",
        "test_loss, test_acc = model.evaluate(X_test, Y_test)\n",
        "print('Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4fb6da9-3d0a-42e2-baef-e659afb25324",
        "id": "IifJBNoz1KG8"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting mnist3.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%run mnist3.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiKRb_aP1Pc_",
        "outputId": "2454221f-2962-4aef-e415-625093d954fb"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60000 train samples\n",
            "10000 test samples\n",
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_layer_1 (Dense)       (None, 64)                50240     \n",
            "                                                                 \n",
            " dense_layer_2 (Dense)       (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_layer_3 (Dense)       (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 55,050\n",
            "Trainable params: 55,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/75\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.6246 - accuracy: 0.5409 - val_loss: 0.8703 - val_accuracy: 0.8139\n",
            "Epoch 2/75\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.6711 - accuracy: 0.8328 - val_loss: 0.4968 - val_accuracy: 0.8739\n",
            "Epoch 3/75\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4742 - accuracy: 0.8717 - val_loss: 0.3979 - val_accuracy: 0.8922\n",
            "Epoch 4/75\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4020 - accuracy: 0.8876 - val_loss: 0.3528 - val_accuracy: 0.9011\n",
            "Epoch 5/75\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3628 - accuracy: 0.8973 - val_loss: 0.3247 - val_accuracy: 0.9072\n",
            "Epoch 6/75\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3374 - accuracy: 0.9039 - val_loss: 0.3065 - val_accuracy: 0.9131\n",
            "Epoch 7/75\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3183 - accuracy: 0.9093 - val_loss: 0.2902 - val_accuracy: 0.9188\n",
            "Epoch 8/75\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3031 - accuracy: 0.9130 - val_loss: 0.2792 - val_accuracy: 0.9208\n",
            "Epoch 9/75\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2904 - accuracy: 0.9165 - val_loss: 0.2687 - val_accuracy: 0.9236\n",
            "Epoch 10/75\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2793 - accuracy: 0.9197 - val_loss: 0.2617 - val_accuracy: 0.9257\n",
            "Epoch 11/75\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2695 - accuracy: 0.9224 - val_loss: 0.2522 - val_accuracy: 0.9275\n",
            "Epoch 12/75\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2604 - accuracy: 0.9246 - val_loss: 0.2447 - val_accuracy: 0.9309\n",
            "Epoch 13/75\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2524 - accuracy: 0.9276 - val_loss: 0.2388 - val_accuracy: 0.9327\n",
            "Epoch 14/75\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2448 - accuracy: 0.9295 - val_loss: 0.2326 - val_accuracy: 0.9341\n",
            "Epoch 15/75\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2379 - accuracy: 0.9319 - val_loss: 0.2270 - val_accuracy: 0.9348\n",
            "Epoch 16/75\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2315 - accuracy: 0.9334 - val_loss: 0.2228 - val_accuracy: 0.9360\n",
            "Epoch 17/75\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2254 - accuracy: 0.9352 - val_loss: 0.2174 - val_accuracy: 0.9377\n",
            "Epoch 18/75\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2196 - accuracy: 0.9358 - val_loss: 0.2124 - val_accuracy: 0.9384\n",
            "Epoch 19/75\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2143 - accuracy: 0.9388 - val_loss: 0.2096 - val_accuracy: 0.9401\n",
            "Epoch 20/75\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2092 - accuracy: 0.9396 - val_loss: 0.2049 - val_accuracy: 0.9421\n",
            "Epoch 21/75\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2042 - accuracy: 0.9411 - val_loss: 0.2004 - val_accuracy: 0.9430\n",
            "Epoch 22/75\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1999 - accuracy: 0.9425 - val_loss: 0.1963 - val_accuracy: 0.9452\n",
            "Epoch 23/75\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1954 - accuracy: 0.9434 - val_loss: 0.1928 - val_accuracy: 0.9467\n",
            "Epoch 24/75\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1912 - accuracy: 0.9449 - val_loss: 0.1895 - val_accuracy: 0.9473\n",
            "Epoch 25/75\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1870 - accuracy: 0.9455 - val_loss: 0.1875 - val_accuracy: 0.9478\n",
            "Epoch 26/75\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1833 - accuracy: 0.9472 - val_loss: 0.1854 - val_accuracy: 0.9481\n",
            "Epoch 27/75\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1797 - accuracy: 0.9478 - val_loss: 0.1803 - val_accuracy: 0.9494\n",
            "Epoch 28/75\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1761 - accuracy: 0.9488 - val_loss: 0.1784 - val_accuracy: 0.9498\n",
            "Epoch 29/75\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1727 - accuracy: 0.9502 - val_loss: 0.1761 - val_accuracy: 0.9503\n",
            "Epoch 30/75\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1692 - accuracy: 0.9515 - val_loss: 0.1727 - val_accuracy: 0.9510\n",
            "Epoch 31/75\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1662 - accuracy: 0.9518 - val_loss: 0.1702 - val_accuracy: 0.9511\n",
            "Epoch 32/75\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1630 - accuracy: 0.9530 - val_loss: 0.1678 - val_accuracy: 0.9521\n",
            "Epoch 33/75\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1599 - accuracy: 0.9540 - val_loss: 0.1653 - val_accuracy: 0.9528\n",
            "Epoch 34/75\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1571 - accuracy: 0.9546 - val_loss: 0.1628 - val_accuracy: 0.9548\n",
            "Epoch 35/75\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1542 - accuracy: 0.9556 - val_loss: 0.1625 - val_accuracy: 0.9533\n",
            "Epoch 36/75\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1514 - accuracy: 0.9566 - val_loss: 0.1591 - val_accuracy: 0.9543\n",
            "Epoch 37/75\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1489 - accuracy: 0.9572 - val_loss: 0.1579 - val_accuracy: 0.9549\n",
            "Epoch 38/75\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1464 - accuracy: 0.9579 - val_loss: 0.1560 - val_accuracy: 0.9551\n",
            "Epoch 39/75\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1440 - accuracy: 0.9590 - val_loss: 0.1548 - val_accuracy: 0.9557\n",
            "Epoch 40/75\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1414 - accuracy: 0.9595 - val_loss: 0.1525 - val_accuracy: 0.9567\n",
            "Epoch 41/75\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1393 - accuracy: 0.9601 - val_loss: 0.1505 - val_accuracy: 0.9576\n",
            "Epoch 42/75\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1371 - accuracy: 0.9613 - val_loss: 0.1493 - val_accuracy: 0.9571\n",
            "Epoch 43/75\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1348 - accuracy: 0.9616 - val_loss: 0.1484 - val_accuracy: 0.9580\n",
            "Epoch 44/75\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1326 - accuracy: 0.9623 - val_loss: 0.1464 - val_accuracy: 0.9575\n",
            "Epoch 45/75\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1305 - accuracy: 0.9631 - val_loss: 0.1461 - val_accuracy: 0.9586\n",
            "Epoch 46/75\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1287 - accuracy: 0.9635 - val_loss: 0.1428 - val_accuracy: 0.9596\n",
            "Epoch 47/75\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1266 - accuracy: 0.9643 - val_loss: 0.1415 - val_accuracy: 0.9594\n",
            "Epoch 48/75\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1244 - accuracy: 0.9651 - val_loss: 0.1405 - val_accuracy: 0.9599\n",
            "Epoch 49/75\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1229 - accuracy: 0.9653 - val_loss: 0.1394 - val_accuracy: 0.9594\n",
            "Epoch 50/75\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1210 - accuracy: 0.9663 - val_loss: 0.1384 - val_accuracy: 0.9606\n",
            "Epoch 51/75\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1193 - accuracy: 0.9665 - val_loss: 0.1370 - val_accuracy: 0.9604\n",
            "Epoch 52/75\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1174 - accuracy: 0.9673 - val_loss: 0.1359 - val_accuracy: 0.9615\n",
            "Epoch 53/75\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1156 - accuracy: 0.9673 - val_loss: 0.1347 - val_accuracy: 0.9614\n",
            "Epoch 54/75\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1142 - accuracy: 0.9682 - val_loss: 0.1335 - val_accuracy: 0.9610\n",
            "Epoch 55/75\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1125 - accuracy: 0.9685 - val_loss: 0.1330 - val_accuracy: 0.9619\n",
            "Epoch 56/75\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1110 - accuracy: 0.9688 - val_loss: 0.1315 - val_accuracy: 0.9616\n",
            "Epoch 57/75\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1095 - accuracy: 0.9700 - val_loss: 0.1310 - val_accuracy: 0.9620\n",
            "Epoch 58/75\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1079 - accuracy: 0.9704 - val_loss: 0.1295 - val_accuracy: 0.9626\n",
            "Epoch 59/75\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1065 - accuracy: 0.9706 - val_loss: 0.1288 - val_accuracy: 0.9628\n",
            "Epoch 60/75\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1052 - accuracy: 0.9709 - val_loss: 0.1275 - val_accuracy: 0.9638\n",
            "Epoch 61/75\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1038 - accuracy: 0.9711 - val_loss: 0.1275 - val_accuracy: 0.9634\n",
            "Epoch 62/75\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1025 - accuracy: 0.9718 - val_loss: 0.1269 - val_accuracy: 0.9635\n",
            "Epoch 63/75\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1012 - accuracy: 0.9723 - val_loss: 0.1251 - val_accuracy: 0.9638\n",
            "Epoch 64/75\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0998 - accuracy: 0.9724 - val_loss: 0.1248 - val_accuracy: 0.9643\n",
            "Epoch 65/75\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0987 - accuracy: 0.9726 - val_loss: 0.1245 - val_accuracy: 0.9642\n",
            "Epoch 66/75\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.0973 - accuracy: 0.9729 - val_loss: 0.1231 - val_accuracy: 0.9639\n",
            "Epoch 67/75\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0960 - accuracy: 0.9732 - val_loss: 0.1225 - val_accuracy: 0.9643\n",
            "Epoch 68/75\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.0949 - accuracy: 0.9739 - val_loss: 0.1220 - val_accuracy: 0.9643\n",
            "Epoch 69/75\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0938 - accuracy: 0.9737 - val_loss: 0.1219 - val_accuracy: 0.9647\n",
            "Epoch 70/75\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.0926 - accuracy: 0.9745 - val_loss: 0.1207 - val_accuracy: 0.9648\n",
            "Epoch 71/75\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.0916 - accuracy: 0.9747 - val_loss: 0.1200 - val_accuracy: 0.9648\n",
            "Epoch 72/75\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.0905 - accuracy: 0.9748 - val_loss: 0.1195 - val_accuracy: 0.9656\n",
            "Epoch 73/75\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.0893 - accuracy: 0.9752 - val_loss: 0.1188 - val_accuracy: 0.9655\n",
            "Epoch 74/75\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0884 - accuracy: 0.9756 - val_loss: 0.1183 - val_accuracy: 0.9657\n",
            "Epoch 75/75\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0875 - accuracy: 0.9759 - val_loss: 0.1173 - val_accuracy: 0.9656\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1078 - accuracy: 0.9658\n",
            "Test accuracy: 0.9657999873161316\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Change Optimizer\n",
        "```\n",
        "model.compile(optimizer='adam',\n",
        "                 loss='categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "dWOY6GuM12TF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile mnist4.py\n",
        "### MNIST Ver 4\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "\n",
        "# for reproducibility\n",
        "np.random.seed(1671)\n",
        "\n",
        "# network and training\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 128\n",
        "VERBOSE = 1\n",
        "NB_CLASSES = 10   # number of outputs = number of digits\n",
        "N_HIDDEN = 64\n",
        "VALIDATION_SPLIT=0.2 # how much TRAIN is reserved for VALIDATION\n",
        "\n",
        "# loading MNIST dataset\n",
        "# verify\n",
        "# the split between train and test is 60,000, and 10,000 respectly \n",
        "# one-hot is automatically applied\n",
        "mnist = keras.datasets.mnist\n",
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')\n",
        "\n",
        "\n",
        "#normalize in [0,1]\n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
        "#X_train is 60000 rows of 28x28 values --> reshaped in 60000 x 784\n",
        "RESHAPED = 784\n",
        "#\n",
        "X_train = X_train.reshape(60000, RESHAPED)\n",
        "X_test = X_test.reshape(10000, RESHAPED)\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "# One-hot representation of the labels.\n",
        "Y_train = tf.keras.utils.to_categorical(Y_train, NB_CLASSES) \n",
        "Y_test = tf.keras.utils.to_categorical(Y_test, NB_CLASSES)\n",
        "\n",
        "model = tf.keras.models.Sequential() \n",
        "model.add(keras.layers.Dense(N_HIDDEN,\n",
        "             input_shape=(RESHAPED,),name='dense_layer_1', activation='relu')) \n",
        "model.add(keras.layers.Dense(N_HIDDEN,name='dense_layer_2', activation='relu')) \n",
        "model.add(keras.layers.Dense(NB_CLASSES,name='dense_layer_3', activation='softmax'))\n",
        "\n",
        "# summary of the model\n",
        "model.summary()\n",
        "\n",
        "# compiling the model\n",
        "model.compile(optimizer='SGD', \n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#training the moodel\n",
        "model.fit(X_train, Y_train,\n",
        "\t\tbatch_size=BATCH_SIZE, epochs=EPOCHS,\n",
        "\t\tverbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
        "\n",
        "#evalute the model\n",
        "test_loss, test_acc = model.evaluate(X_test, Y_test)\n",
        "print('Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1174d30-1a77-4921-bc84-c236ac6f8f14",
        "id": "xGSM0cIE2zbr"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting mnist4.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%run mnist4.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gvq3SBNo21jf",
        "outputId": "d35843dc-328f-47ff-dbc7-b8a6da605eda"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60000 train samples\n",
            "10000 test samples\n",
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_layer_1 (Dense)       (None, 64)                50240     \n",
            "                                                                 \n",
            " dense_layer_2 (Dense)       (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_layer_3 (Dense)       (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 55,050\n",
            "Trainable params: 55,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.6079 - accuracy: 0.5513 - val_loss: 0.8837 - val_accuracy: 0.7930\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6664 - accuracy: 0.8309 - val_loss: 0.4881 - val_accuracy: 0.8745\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4643 - accuracy: 0.8744 - val_loss: 0.3920 - val_accuracy: 0.8912\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3946 - accuracy: 0.8908 - val_loss: 0.3479 - val_accuracy: 0.9015\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.3582 - accuracy: 0.8988 - val_loss: 0.3244 - val_accuracy: 0.9068\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3343 - accuracy: 0.9048 - val_loss: 0.3045 - val_accuracy: 0.9128\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3164 - accuracy: 0.9103 - val_loss: 0.2913 - val_accuracy: 0.9171\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3018 - accuracy: 0.9142 - val_loss: 0.2783 - val_accuracy: 0.9194\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2894 - accuracy: 0.9173 - val_loss: 0.2682 - val_accuracy: 0.9231\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2787 - accuracy: 0.9205 - val_loss: 0.2595 - val_accuracy: 0.9248\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2685 - accuracy: 0.9234 - val_loss: 0.2516 - val_accuracy: 0.9278\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2594 - accuracy: 0.9256 - val_loss: 0.2445 - val_accuracy: 0.9302\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2514 - accuracy: 0.9286 - val_loss: 0.2378 - val_accuracy: 0.9319\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2433 - accuracy: 0.9307 - val_loss: 0.2322 - val_accuracy: 0.9334\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2361 - accuracy: 0.9326 - val_loss: 0.2273 - val_accuracy: 0.9343\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2297 - accuracy: 0.9344 - val_loss: 0.2208 - val_accuracy: 0.9364\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2234 - accuracy: 0.9364 - val_loss: 0.2152 - val_accuracy: 0.9380\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2173 - accuracy: 0.9383 - val_loss: 0.2105 - val_accuracy: 0.9388\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2118 - accuracy: 0.9398 - val_loss: 0.2070 - val_accuracy: 0.9398\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2064 - accuracy: 0.9416 - val_loss: 0.2033 - val_accuracy: 0.9417\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2014 - accuracy: 0.9430 - val_loss: 0.1980 - val_accuracy: 0.9423\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1964 - accuracy: 0.9442 - val_loss: 0.1943 - val_accuracy: 0.9434\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1916 - accuracy: 0.9455 - val_loss: 0.1911 - val_accuracy: 0.9453\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1871 - accuracy: 0.9466 - val_loss: 0.1883 - val_accuracy: 0.9465\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1831 - accuracy: 0.9479 - val_loss: 0.1842 - val_accuracy: 0.9471\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1789 - accuracy: 0.9490 - val_loss: 0.1801 - val_accuracy: 0.9477\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1750 - accuracy: 0.9501 - val_loss: 0.1769 - val_accuracy: 0.9498\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1714 - accuracy: 0.9510 - val_loss: 0.1734 - val_accuracy: 0.9502\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1678 - accuracy: 0.9518 - val_loss: 0.1711 - val_accuracy: 0.9501\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1644 - accuracy: 0.9531 - val_loss: 0.1684 - val_accuracy: 0.9509\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1610 - accuracy: 0.9537 - val_loss: 0.1662 - val_accuracy: 0.9517\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1580 - accuracy: 0.9546 - val_loss: 0.1633 - val_accuracy: 0.9526\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1547 - accuracy: 0.9554 - val_loss: 0.1619 - val_accuracy: 0.9532\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1516 - accuracy: 0.9565 - val_loss: 0.1586 - val_accuracy: 0.9541\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1488 - accuracy: 0.9573 - val_loss: 0.1569 - val_accuracy: 0.9546\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1461 - accuracy: 0.9580 - val_loss: 0.1546 - val_accuracy: 0.9544\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1434 - accuracy: 0.9589 - val_loss: 0.1528 - val_accuracy: 0.9553\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1408 - accuracy: 0.9596 - val_loss: 0.1514 - val_accuracy: 0.9557\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1385 - accuracy: 0.9603 - val_loss: 0.1495 - val_accuracy: 0.9572\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1361 - accuracy: 0.9609 - val_loss: 0.1473 - val_accuracy: 0.9577\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1339 - accuracy: 0.9611 - val_loss: 0.1463 - val_accuracy: 0.9571\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1314 - accuracy: 0.9624 - val_loss: 0.1451 - val_accuracy: 0.9578\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1291 - accuracy: 0.9631 - val_loss: 0.1440 - val_accuracy: 0.9582\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1273 - accuracy: 0.9634 - val_loss: 0.1424 - val_accuracy: 0.9591\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1253 - accuracy: 0.9635 - val_loss: 0.1396 - val_accuracy: 0.9605\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1233 - accuracy: 0.9646 - val_loss: 0.1396 - val_accuracy: 0.9606\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1213 - accuracy: 0.9654 - val_loss: 0.1381 - val_accuracy: 0.9605\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1194 - accuracy: 0.9662 - val_loss: 0.1368 - val_accuracy: 0.9603\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1177 - accuracy: 0.9664 - val_loss: 0.1362 - val_accuracy: 0.9611\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1158 - accuracy: 0.9669 - val_loss: 0.1343 - val_accuracy: 0.9617\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1294 - accuracy: 0.9611\n",
            "Test accuracy: 0.9610999822616577\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Change Learning Rate\n",
        "\n",
        "```\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "OPTMIZER = SGD(lr=0.001)\n",
        ":\n",
        ":\n",
        ":\n",
        "# compiling the model\n",
        "model.compile(optimizer=OPTMIZER, \n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "```\n"
      ],
      "metadata": {
        "id": "S5vcTx9r3K4b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile mnist5.py\n",
        "### MNIST Ver 5\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "OPTMIZER = SGD(lr=0.001)\n",
        "# for reproducibility\n",
        "np.random.seed(1671)\n",
        "\n",
        "# network and training\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 128\n",
        "VERBOSE = 1\n",
        "NB_CLASSES = 10   # number of outputs = number of digits\n",
        "N_HIDDEN = 64\n",
        "VALIDATION_SPLIT=0.2 # how much TRAIN is reserved for VALIDATION\n",
        "\n",
        "# loading MNIST dataset\n",
        "# verify\n",
        "# the split between train and test is 60,000, and 10,000 respectly \n",
        "# one-hot is automatically applied\n",
        "mnist = keras.datasets.mnist\n",
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')\n",
        "\n",
        "\n",
        "#normalize in [0,1]\n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
        "#X_train is 60000 rows of 28x28 values --> reshaped in 60000 x 784\n",
        "RESHAPED = 784\n",
        "#\n",
        "X_train = X_train.reshape(60000, RESHAPED)\n",
        "X_test = X_test.reshape(10000, RESHAPED)\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "# One-hot representation of the labels.\n",
        "Y_train = tf.keras.utils.to_categorical(Y_train, NB_CLASSES) \n",
        "Y_test = tf.keras.utils.to_categorical(Y_test, NB_CLASSES)\n",
        "\n",
        "model = tf.keras.models.Sequential() \n",
        "model.add(keras.layers.Dense(N_HIDDEN,\n",
        "             input_shape=(RESHAPED,),name='dense_layer_1', activation='relu')) \n",
        "model.add(keras.layers.Dense(N_HIDDEN,name='dense_layer_2', activation='relu')) \n",
        "model.add(keras.layers.Dense(NB_CLASSES,name='dense_layer_3', activation='softmax'))\n",
        "\n",
        "# summary of the model\n",
        "model.summary()\n",
        "\n",
        "# compiling the model\n",
        "model.compile(optimizer=OPTMIZER, \n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#training the moodel\n",
        "model.fit(X_train, Y_train,\n",
        "\t\tbatch_size=BATCH_SIZE, epochs=EPOCHS,\n",
        "\t\tverbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
        "\n",
        "#evalute the model\n",
        "test_loss, test_acc = model.evaluate(X_test, Y_test)\n",
        "print('Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66e74627-9bf2-40f4-aace-a7eb4321b331",
        "id": "-eVqgxnO3lY9"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting mnist5.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%run mnist5.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sg2ydSEA3t0A",
        "outputId": "4d2d3444-1f17-4d45-b391-a28b54a8107f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60000 train samples\n",
            "10000 test samples\n",
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_layer_1 (Dense)       (None, 64)                50240     \n",
            "                                                                 \n",
            " dense_layer_2 (Dense)       (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_layer_3 (Dense)       (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 55,050\n",
            "Trainable params: 55,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2579 - accuracy: 0.1498 - val_loss: 2.1803 - val_accuracy: 0.2509\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.1049 - accuracy: 0.3605 - val_loss: 2.0213 - val_accuracy: 0.4751\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.9369 - accuracy: 0.5422 - val_loss: 1.8340 - val_accuracy: 0.6182\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.7424 - accuracy: 0.6482 - val_loss: 1.6247 - val_accuracy: 0.6957\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.5341 - accuracy: 0.7066 - val_loss: 1.4106 - val_accuracy: 0.7398\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.3320 - accuracy: 0.7422 - val_loss: 1.2140 - val_accuracy: 0.7692\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.1551 - accuracy: 0.7673 - val_loss: 1.0500 - val_accuracy: 0.7907\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.0119 - accuracy: 0.7860 - val_loss: 0.9214 - val_accuracy: 0.8092\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.9007 - accuracy: 0.8016 - val_loss: 0.8225 - val_accuracy: 0.8242\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.8149 - accuracy: 0.8147 - val_loss: 0.7459 - val_accuracy: 0.8332\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.7479 - accuracy: 0.8247 - val_loss: 0.6859 - val_accuracy: 0.8426\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6948 - accuracy: 0.8334 - val_loss: 0.6381 - val_accuracy: 0.8502\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6520 - accuracy: 0.8411 - val_loss: 0.5996 - val_accuracy: 0.8558\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6169 - accuracy: 0.8468 - val_loss: 0.5677 - val_accuracy: 0.8618\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5875 - accuracy: 0.8522 - val_loss: 0.5413 - val_accuracy: 0.8656\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5626 - accuracy: 0.8563 - val_loss: 0.5188 - val_accuracy: 0.8690\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5413 - accuracy: 0.8606 - val_loss: 0.4992 - val_accuracy: 0.8723\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5228 - accuracy: 0.8641 - val_loss: 0.4824 - val_accuracy: 0.8755\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5065 - accuracy: 0.8672 - val_loss: 0.4676 - val_accuracy: 0.8783\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4922 - accuracy: 0.8701 - val_loss: 0.4544 - val_accuracy: 0.8803\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4793 - accuracy: 0.8733 - val_loss: 0.4427 - val_accuracy: 0.8814\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4677 - accuracy: 0.8752 - val_loss: 0.4322 - val_accuracy: 0.8841\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4572 - accuracy: 0.8770 - val_loss: 0.4226 - val_accuracy: 0.8864\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4477 - accuracy: 0.8791 - val_loss: 0.4139 - val_accuracy: 0.8883\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4389 - accuracy: 0.8812 - val_loss: 0.4060 - val_accuracy: 0.8895\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4308 - accuracy: 0.8833 - val_loss: 0.3990 - val_accuracy: 0.8903\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4234 - accuracy: 0.8848 - val_loss: 0.3921 - val_accuracy: 0.8918\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4165 - accuracy: 0.8869 - val_loss: 0.3862 - val_accuracy: 0.8926\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4101 - accuracy: 0.8877 - val_loss: 0.3800 - val_accuracy: 0.8942\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4040 - accuracy: 0.8893 - val_loss: 0.3747 - val_accuracy: 0.8952\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3984 - accuracy: 0.8904 - val_loss: 0.3696 - val_accuracy: 0.8965\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3932 - accuracy: 0.8920 - val_loss: 0.3649 - val_accuracy: 0.8973\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3881 - accuracy: 0.8930 - val_loss: 0.3605 - val_accuracy: 0.8995\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3834 - accuracy: 0.8942 - val_loss: 0.3561 - val_accuracy: 0.9000\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3789 - accuracy: 0.8950 - val_loss: 0.3522 - val_accuracy: 0.9007\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3747 - accuracy: 0.8960 - val_loss: 0.3485 - val_accuracy: 0.9018\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.3706 - accuracy: 0.8970 - val_loss: 0.3447 - val_accuracy: 0.9028\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3668 - accuracy: 0.8980 - val_loss: 0.3414 - val_accuracy: 0.9043\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3631 - accuracy: 0.8988 - val_loss: 0.3379 - val_accuracy: 0.9049\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.3596 - accuracy: 0.8997 - val_loss: 0.3349 - val_accuracy: 0.9062\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.3561 - accuracy: 0.9005 - val_loss: 0.3323 - val_accuracy: 0.9062\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3529 - accuracy: 0.9009 - val_loss: 0.3291 - val_accuracy: 0.9074\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3498 - accuracy: 0.9021 - val_loss: 0.3265 - val_accuracy: 0.9084\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3467 - accuracy: 0.9029 - val_loss: 0.3238 - val_accuracy: 0.9082\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3439 - accuracy: 0.9036 - val_loss: 0.3210 - val_accuracy: 0.9097\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3411 - accuracy: 0.9046 - val_loss: 0.3188 - val_accuracy: 0.9105\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3384 - accuracy: 0.9050 - val_loss: 0.3162 - val_accuracy: 0.9114\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.3357 - accuracy: 0.9057 - val_loss: 0.3140 - val_accuracy: 0.9109\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3332 - accuracy: 0.9064 - val_loss: 0.3118 - val_accuracy: 0.9120\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3308 - accuracy: 0.9071 - val_loss: 0.3097 - val_accuracy: 0.9137\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3117 - accuracy: 0.9136\n",
            "Test accuracy: 0.9136000275611877\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add Regularization\n",
        " * L1/L2\n",
        "  \n",
        "  There are three different types of regularization used in machine learning:\n",
        "  * L1 regularization (also known as LASSO): The complexity of the model is expressed as the sum of the absolute values of the weights.\n",
        "  * L2 regularization (also known as Ridge): The complexity of the model is expressed as the sum of the squares of the weights\n",
        "  * Elastic regularization: The complexity of the model is captured by a combination of the preceding two techniques\n",
        " ```\n",
        "from tf.keras.regularizers import l2, activity_l2 \n",
        "model.add(Dense(64, input_dim=64, W_regularizer=l2(0.01), activity_regularizer=activity_l2(0.01)))\n",
        " ```\n",
        "\n",
        "\n",
        "## Add Special Layers\n",
        " * Dropout Layer\n",
        "```\n",
        "model.add(keras.layers.Dropout(DROPOUT))\n",
        "```\n",
        " * Batchnormalization Layer\n",
        "```\n",
        "model.add(keras.layers.BatchNormalization()\n",
        "```\n"
      ],
      "metadata": {
        "id": "7n3ILM3Y3Vxc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "y7DjshAE5Leo"
      },
      "execution_count": 34,
      "outputs": []
    }
  ]
}