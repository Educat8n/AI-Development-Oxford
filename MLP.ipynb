{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNNrIelxitlJNbuQpUf4AzW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Educat8n/AI-Development-Oxford/blob/main/MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining a simple neural network in TensorFlow 2.0\n",
        "\n",
        "* We use TensorFlow 2.0 to define a network that recognizes MNIST handwritten digits. \n",
        "* We start with a very simple neural network and then progressively improve it.\n",
        "* Load the dataset.\n",
        "```\n",
        "mnist = keras.datasets.mnist\n",
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
        "```\n",
        "* X_train is used for fine-tuning our net, and test sets, X_test, used for assessing the performance. \n",
        "* Data is converted into float32 to use 32-bit precision when training a neural network and normalized to the range [0,1]. \n",
        "```\n",
        "#normalize in [0,1]\n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
        "#X_train is 60000 rows of 28x28 values --> reshaped in 60000 x 784\n",
        "RESHAPED = 784\n",
        "#\n",
        "X_train = X_train.reshape(60000, RESHAPED)\n",
        "X_test = X_test.reshape(10000, RESHAPED)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "```\n",
        "* Perform a one-hot encoding on labels Y_train and Y_test.\n",
        "```\n",
        "# One-hot representation of the labels.\n",
        "Y_train = tf.keras.utils.to_categorical(Y_train, NB_CLASSES) Y_test = tf.keras.utils.to_categorical(Y_test, NB_CLASSES)\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dkfq7QeRnQsS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "mnist = keras.datasets.mnist\n",
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
        "print(X_train.shape, Y_train.shape, 'train samples')\n",
        "print(X_test.shape, Y_test.shape, 'test samples')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sl1G0tdOpHO0",
        "outputId": "9c99a4d5-0b38-4864-95e1-fbd82db603dd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28) (60000,) train samples\n",
            "(10000, 28, 28) (10000,) test samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYiPq5ZM7eVG",
        "outputId": "07116eb3-47cf-46ce-8e0f-f02b083ca5db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting mnist0.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile mnist0.py\n",
        "### MNIST Ver 0\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "\n",
        "# for reproducibility\n",
        "np.random.seed(1671)\n",
        "\n",
        "# network and training\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 128\n",
        "VERBOSE = 1\n",
        "NB_CLASSES = 10   # number of outputs = number of digits\n",
        "N_HIDDEN = 128\n",
        "VALIDATION_SPLIT=0.2 # how much TRAIN is reserved for VALIDATION\n",
        "\n",
        "# loading MNIST dataset\n",
        "# verify\n",
        "# the split between train and test is 60,000, and 10,000 respectly \n",
        "# one-hot is automatically applied\n",
        "mnist = keras.datasets.mnist\n",
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')\n",
        "\n",
        "\n",
        "#normalize in [0,1]\n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
        "#X_train is 60000 rows of 28x28 values --> reshaped in 60000 x 784\n",
        "RESHAPED = 784\n",
        "#\n",
        "X_train = X_train.reshape(60000, RESHAPED)\n",
        "X_test = X_test.reshape(10000, RESHAPED)\n",
        "print(Y_train[1])\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "# One-hot representation of the labels.\n",
        "Y_train = tf.keras.utils.to_categorical(Y_train, NB_CLASSES) \n",
        "Y_test = tf.keras.utils.to_categorical(Y_test, NB_CLASSES)\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(keras.layers.Dense(NB_CLASSES,\n",
        "   \t\tinput_shape=(RESHAPED,), kernel_initializer='zeros',\n",
        "   \t\tname='dense_layer', activation='softmax'))\n",
        "\n",
        "# summary of the model\n",
        "model.summary()\n",
        "\n",
        "# compiling the model\n",
        "model.compile(optimizer='SGD', \n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#training the moodel\n",
        "model.fit(X_train, Y_train,\n",
        "\t\tbatch_size=BATCH_SIZE, epochs=EPOCHS,\n",
        "\t\tverbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
        "\n",
        "#evalute the model\n",
        "test_loss, test_acc = model.evaluate(X_test, Y_test)\n",
        "print('Test accuracy:', test_acc)\n",
        "\n",
        "# making prediction\n",
        "#predictions = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%run mnist0.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6DgOu_THETR",
        "outputId": "a474dfe6-2b96-423d-b875-3ab684efcbd6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60000 train samples\n",
            "10000 test samples\n",
            "0\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_layer (Dense)         (None, 10)                7850      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,850\n",
            "Trainable params: 7,850\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 1.3527 - accuracy: 0.7781 - val_loss: 0.8779 - val_accuracy: 0.8438\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7803 - accuracy: 0.8424 - val_loss: 0.6476 - val_accuracy: 0.8642\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6349 - accuracy: 0.8574 - val_loss: 0.5546 - val_accuracy: 0.8753\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.5645 - accuracy: 0.8657 - val_loss: 0.5035 - val_accuracy: 0.8807\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.5216 - accuracy: 0.8718 - val_loss: 0.4701 - val_accuracy: 0.8852\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4920 - accuracy: 0.8769 - val_loss: 0.4466 - val_accuracy: 0.8887\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4702 - accuracy: 0.8801 - val_loss: 0.4288 - val_accuracy: 0.8917\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4532 - accuracy: 0.8826 - val_loss: 0.4149 - val_accuracy: 0.8944\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4395 - accuracy: 0.8850 - val_loss: 0.4038 - val_accuracy: 0.8966\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4282 - accuracy: 0.8873 - val_loss: 0.3943 - val_accuracy: 0.8982\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4186 - accuracy: 0.8888 - val_loss: 0.3864 - val_accuracy: 0.9003\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4104 - accuracy: 0.8908 - val_loss: 0.3796 - val_accuracy: 0.9010\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4032 - accuracy: 0.8920 - val_loss: 0.3736 - val_accuracy: 0.9019\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3969 - accuracy: 0.8933 - val_loss: 0.3684 - val_accuracy: 0.9027\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3912 - accuracy: 0.8946 - val_loss: 0.3637 - val_accuracy: 0.9040\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3861 - accuracy: 0.8952 - val_loss: 0.3597 - val_accuracy: 0.9037\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3815 - accuracy: 0.8964 - val_loss: 0.3557 - val_accuracy: 0.9048\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3773 - accuracy: 0.8971 - val_loss: 0.3522 - val_accuracy: 0.9061\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3734 - accuracy: 0.8984 - val_loss: 0.3492 - val_accuracy: 0.9062\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3699 - accuracy: 0.8988 - val_loss: 0.3460 - val_accuracy: 0.9068\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3667 - accuracy: 0.8996 - val_loss: 0.3434 - val_accuracy: 0.9072\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3636 - accuracy: 0.9001 - val_loss: 0.3410 - val_accuracy: 0.9082\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3608 - accuracy: 0.9007 - val_loss: 0.3386 - val_accuracy: 0.9083\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3581 - accuracy: 0.9013 - val_loss: 0.3364 - val_accuracy: 0.9084\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3556 - accuracy: 0.9019 - val_loss: 0.3344 - val_accuracy: 0.9097\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3533 - accuracy: 0.9023 - val_loss: 0.3325 - val_accuracy: 0.9097\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3510 - accuracy: 0.9029 - val_loss: 0.3307 - val_accuracy: 0.9107\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3489 - accuracy: 0.9032 - val_loss: 0.3290 - val_accuracy: 0.9109\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3470 - accuracy: 0.9040 - val_loss: 0.3274 - val_accuracy: 0.9113\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3451 - accuracy: 0.9044 - val_loss: 0.3260 - val_accuracy: 0.9115\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3433 - accuracy: 0.9049 - val_loss: 0.3244 - val_accuracy: 0.9122\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3416 - accuracy: 0.9054 - val_loss: 0.3231 - val_accuracy: 0.9122\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3400 - accuracy: 0.9060 - val_loss: 0.3218 - val_accuracy: 0.9118\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3384 - accuracy: 0.9061 - val_loss: 0.3206 - val_accuracy: 0.9128\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3370 - accuracy: 0.9066 - val_loss: 0.3194 - val_accuracy: 0.9128\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3355 - accuracy: 0.9071 - val_loss: 0.3182 - val_accuracy: 0.9132\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3341 - accuracy: 0.9074 - val_loss: 0.3171 - val_accuracy: 0.9133\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3328 - accuracy: 0.9073 - val_loss: 0.3160 - val_accuracy: 0.9139\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3315 - accuracy: 0.9076 - val_loss: 0.3152 - val_accuracy: 0.9135\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3304 - accuracy: 0.9082 - val_loss: 0.3140 - val_accuracy: 0.9142\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3292 - accuracy: 0.9084 - val_loss: 0.3132 - val_accuracy: 0.9147\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3280 - accuracy: 0.9087 - val_loss: 0.3122 - val_accuracy: 0.9147\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3269 - accuracy: 0.9094 - val_loss: 0.3115 - val_accuracy: 0.9146\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3259 - accuracy: 0.9096 - val_loss: 0.3105 - val_accuracy: 0.9153\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3249 - accuracy: 0.9100 - val_loss: 0.3099 - val_accuracy: 0.9147\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3239 - accuracy: 0.9100 - val_loss: 0.3090 - val_accuracy: 0.9150\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3230 - accuracy: 0.9105 - val_loss: 0.3083 - val_accuracy: 0.9149\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3220 - accuracy: 0.9104 - val_loss: 0.3075 - val_accuracy: 0.9158\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3211 - accuracy: 0.9107 - val_loss: 0.3068 - val_accuracy: 0.9157\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3203 - accuracy: 0.9111 - val_loss: 0.3062 - val_accuracy: 0.9154\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3061 - accuracy: 0.9163\n",
            "Test accuracy: 0.9162999987602234\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Improving Model Performance- Hyperparameter Tuning\n",
        "\n",
        "* Model Architecture\n",
        "  * Change Number of hidden layers\n",
        "  * Change number of hidden units/neurons\n",
        "\n",
        "\n",
        "* Epochs\n",
        "* Batch-Size\n",
        "```\n",
        "model.fit(X_train, Y_train,\n",
        "\t\tbatch_size=BATCH_SIZE, epochs=EPOCHS,\n",
        "\t\tverbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
        "    ```\n",
        "\n",
        "* Optimizer\n",
        " * SGD\n",
        " * Adam\n",
        " * Adadelta\n",
        "```\n",
        "model.compile(optimizer='SGD',\n",
        "                 loss='categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "```\n",
        "* Learning Rate\n",
        "```\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "OPTMIZER = SGD(lr=0.001)\n",
        ":\n",
        ":\n",
        ":\n",
        "# compiling the model\n",
        "model.compile(optimizer=OPTMIZER, \n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "```\n",
        "\n",
        "* Regularization\n",
        " * L1/L2\n",
        " * Dropout Layer\n",
        " * Batchnormalization Layer\n"
      ],
      "metadata": {
        "id": "NnFF74DVuGHA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Change Number of hidden layers.\n",
        "```\n",
        "# Build the model.\n",
        "model = tf.keras.models.Sequential() \n",
        "model.add(keras.layers.Dense(N_HIDDEN,\n",
        "             input_shape=(RESHAPED,),name='dense_layer', activation='relu')) \n",
        "model.add(keras.layers.Dense(N_HIDDEN,name='dense_layer_2', activation='relu')) \n",
        "model.add(keras.layers.Dense(NB_CLASSES,name='dense_layer_3', activation='softmax'))\n",
        "# Summary of the model. \n",
        "model.summary()\n",
        "```\n"
      ],
      "metadata": {
        "id": "iV4qGBbhsFRl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile mnist1.py\n",
        "### MNIST Ver 1\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "\n",
        "# for reproducibility\n",
        "np.random.seed(1671)\n",
        "\n",
        "# network and training\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 128\n",
        "VERBOSE = 1\n",
        "NB_CLASSES = 10   # number of outputs = number of digits\n",
        "N_HIDDEN = 128\n",
        "VALIDATION_SPLIT=0.2 # how much TRAIN is reserved for VALIDATION\n",
        "\n",
        "# loading MNIST dataset\n",
        "# verify\n",
        "# the split between train and test is 60,000, and 10,000 respectly \n",
        "# one-hot is automatically applied\n",
        "mnist = keras.datasets.mnist\n",
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')\n",
        "\n",
        "\n",
        "#normalize in [0,1]\n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
        "#X_train is 60000 rows of 28x28 values --> reshaped in 60000 x 784\n",
        "RESHAPED = 784\n",
        "#\n",
        "X_train = X_train.reshape(60000, RESHAPED)\n",
        "X_test = X_test.reshape(10000, RESHAPED)\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "# One-hot representation of the labels.\n",
        "Y_train = tf.keras.utils.to_categorical(Y_train, NB_CLASSES) \n",
        "Y_test = tf.keras.utils.to_categorical(Y_test, NB_CLASSES)\n",
        "\n",
        "model = tf.keras.models.Sequential() \n",
        "model.add(keras.layers.Dense(N_HIDDEN,\n",
        "             input_shape=(RESHAPED,),name='dense_layer_1', activation='relu')) \n",
        "model.add(keras.layers.Dense(N_HIDDEN,name='dense_layer_2', activation='relu')) \n",
        "model.add(keras.layers.Dense(NB_CLASSES,name='dense_layer_3', activation='softmax'))\n",
        "\n",
        "# summary of the model\n",
        "model.summary()\n",
        "\n",
        "# compiling the model\n",
        "model.compile(optimizer='SGD', \n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#training the moodel\n",
        "model.fit(X_train, Y_train,\n",
        "\t\tbatch_size=BATCH_SIZE, epochs=EPOCHS,\n",
        "\t\tverbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
        "\n",
        "#evalute the model\n",
        "test_loss, test_acc = model.evaluate(X_test, Y_test)\n",
        "print('Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EaKEj7e3sEel",
        "outputId": "0bfd04bc-a626-4dd8-f146-a3ef1cd71924"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting mnist1.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%run mnist1.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCypoPkhHGYz",
        "outputId": "d46133d4-8dc5-4727-b3d5-f97242c73e30"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60000 train samples\n",
            "10000 test samples\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_layer_1 (Dense)       (None, 128)               100480    \n",
            "                                                                 \n",
            " dense_layer_2 (Dense)       (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_layer_3 (Dense)       (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 118,282\n",
            "Trainable params: 118,282\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.4708 - accuracy: 0.6244 - val_loss: 0.7513 - val_accuracy: 0.8412\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5959 - accuracy: 0.8531 - val_loss: 0.4573 - val_accuracy: 0.8842\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4389 - accuracy: 0.8815 - val_loss: 0.3764 - val_accuracy: 0.8988\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3794 - accuracy: 0.8943 - val_loss: 0.3377 - val_accuracy: 0.9068\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.3462 - accuracy: 0.9031 - val_loss: 0.3134 - val_accuracy: 0.9108\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.3237 - accuracy: 0.9074 - val_loss: 0.2977 - val_accuracy: 0.9147\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.3064 - accuracy: 0.9128 - val_loss: 0.2832 - val_accuracy: 0.9197\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2924 - accuracy: 0.9167 - val_loss: 0.2718 - val_accuracy: 0.9224\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2802 - accuracy: 0.9197 - val_loss: 0.2643 - val_accuracy: 0.9243\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2694 - accuracy: 0.9232 - val_loss: 0.2534 - val_accuracy: 0.9282\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.2595 - accuracy: 0.9258 - val_loss: 0.2451 - val_accuracy: 0.9293\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2507 - accuracy: 0.9285 - val_loss: 0.2380 - val_accuracy: 0.9325\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2423 - accuracy: 0.9311 - val_loss: 0.2302 - val_accuracy: 0.9344\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.2344 - accuracy: 0.9334 - val_loss: 0.2246 - val_accuracy: 0.9362\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2273 - accuracy: 0.9354 - val_loss: 0.2193 - val_accuracy: 0.9373\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2206 - accuracy: 0.9372 - val_loss: 0.2132 - val_accuracy: 0.9391\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2140 - accuracy: 0.9390 - val_loss: 0.2097 - val_accuracy: 0.9398\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2082 - accuracy: 0.9412 - val_loss: 0.2040 - val_accuracy: 0.9416\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2023 - accuracy: 0.9421 - val_loss: 0.1994 - val_accuracy: 0.9443\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1966 - accuracy: 0.9439 - val_loss: 0.1948 - val_accuracy: 0.9453\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1913 - accuracy: 0.9448 - val_loss: 0.1912 - val_accuracy: 0.9453\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1865 - accuracy: 0.9466 - val_loss: 0.1876 - val_accuracy: 0.9471\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1817 - accuracy: 0.9477 - val_loss: 0.1837 - val_accuracy: 0.9480\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1771 - accuracy: 0.9491 - val_loss: 0.1791 - val_accuracy: 0.9492\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1726 - accuracy: 0.9510 - val_loss: 0.1755 - val_accuracy: 0.9506\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1685 - accuracy: 0.9524 - val_loss: 0.1718 - val_accuracy: 0.9514\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1643 - accuracy: 0.9532 - val_loss: 0.1690 - val_accuracy: 0.9525\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1603 - accuracy: 0.9545 - val_loss: 0.1659 - val_accuracy: 0.9534\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1568 - accuracy: 0.9554 - val_loss: 0.1626 - val_accuracy: 0.9542\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1530 - accuracy: 0.9567 - val_loss: 0.1601 - val_accuracy: 0.9548\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1495 - accuracy: 0.9572 - val_loss: 0.1570 - val_accuracy: 0.9558\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1461 - accuracy: 0.9585 - val_loss: 0.1550 - val_accuracy: 0.9563\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1428 - accuracy: 0.9596 - val_loss: 0.1526 - val_accuracy: 0.9576\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1397 - accuracy: 0.9607 - val_loss: 0.1505 - val_accuracy: 0.9576\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1366 - accuracy: 0.9613 - val_loss: 0.1489 - val_accuracy: 0.9570\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1337 - accuracy: 0.9622 - val_loss: 0.1457 - val_accuracy: 0.9579\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1308 - accuracy: 0.9634 - val_loss: 0.1440 - val_accuracy: 0.9597\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1281 - accuracy: 0.9637 - val_loss: 0.1415 - val_accuracy: 0.9609\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1253 - accuracy: 0.9649 - val_loss: 0.1400 - val_accuracy: 0.9604\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1229 - accuracy: 0.9651 - val_loss: 0.1379 - val_accuracy: 0.9613\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1203 - accuracy: 0.9661 - val_loss: 0.1352 - val_accuracy: 0.9626\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1181 - accuracy: 0.9672 - val_loss: 0.1339 - val_accuracy: 0.9625\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1155 - accuracy: 0.9671 - val_loss: 0.1329 - val_accuracy: 0.9625\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1134 - accuracy: 0.9686 - val_loss: 0.1302 - val_accuracy: 0.9635\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1111 - accuracy: 0.9692 - val_loss: 0.1287 - val_accuracy: 0.9642\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1090 - accuracy: 0.9701 - val_loss: 0.1278 - val_accuracy: 0.9644\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1070 - accuracy: 0.9707 - val_loss: 0.1274 - val_accuracy: 0.9641\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1049 - accuracy: 0.9710 - val_loss: 0.1252 - val_accuracy: 0.9653\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1030 - accuracy: 0.9715 - val_loss: 0.1235 - val_accuracy: 0.9650\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1012 - accuracy: 0.9720 - val_loss: 0.1223 - val_accuracy: 0.9655\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1177 - accuracy: 0.9650\n",
            "Test accuracy: 0.9649999737739563\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Change number of hidden units\n",
        "\n",
        "```\n",
        "N_HIDDEN = 64\n",
        ":\n",
        ":\n",
        "# Build the model.\n",
        "model = tf.keras.models.Sequential() \n",
        "model.add(keras.layers.Dense(N_HIDDEN,\n",
        "             input_shape=(RESHAPED,),name='dense_layer', activation='relu')) \n",
        "model.add(keras.layers.Dense(N_HIDDEN,name='dense_layer_2', activation='relu')) \n",
        "model.add(keras.layers.Dense(NB_CLASSES,name='dense_layer_3', activation='softmax'))\n",
        "# Summary of the model. \n",
        "model.summary()\n",
        "```\n"
      ],
      "metadata": {
        "id": "hCVprsAOyKHv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile mnist2.py\n",
        "### MNIST Ver 2\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "\n",
        "# for reproducibility\n",
        "np.random.seed(1671)\n",
        "\n",
        "# network and training\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 128\n",
        "VERBOSE = 1\n",
        "NB_CLASSES = 10   # number of outputs = number of digits\n",
        "N_HIDDEN = 64\n",
        "VALIDATION_SPLIT=0.2 # how much TRAIN is reserved for VALIDATION\n",
        "\n",
        "# loading MNIST dataset\n",
        "# verify\n",
        "# the split between train and test is 60,000, and 10,000 respectly \n",
        "# one-hot is automatically applied\n",
        "mnist = keras.datasets.mnist\n",
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')\n",
        "\n",
        "\n",
        "#normalize in [0,1]\n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
        "#X_train is 60000 rows of 28x28 values --> reshaped in 60000 x 784\n",
        "RESHAPED = 784\n",
        "#\n",
        "X_train = X_train.reshape(60000, RESHAPED)\n",
        "X_test = X_test.reshape(10000, RESHAPED)\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "# One-hot representation of the labels.\n",
        "Y_train = tf.keras.utils.to_categorical(Y_train, NB_CLASSES) \n",
        "Y_test = tf.keras.utils.to_categorical(Y_test, NB_CLASSES)\n",
        "\n",
        "model = tf.keras.models.Sequential() \n",
        "model.add(keras.layers.Dense(N_HIDDEN,\n",
        "             input_shape=(RESHAPED,),name='dense_layer_1', activation='relu')) \n",
        "model.add(keras.layers.Dense(N_HIDDEN,name='dense_layer_2', activation='relu')) \n",
        "model.add(keras.layers.Dense(NB_CLASSES,name='dense_layer_3', activation='softmax'))\n",
        "\n",
        "# summary of the model\n",
        "model.summary()\n",
        "\n",
        "# compiling the model\n",
        "model.compile(optimizer='SGD', \n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#training the moodel\n",
        "model.fit(X_train, Y_train,\n",
        "\t\tbatch_size=BATCH_SIZE, epochs=EPOCHS,\n",
        "\t\tverbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
        "\n",
        "#evalute the model\n",
        "test_loss, test_acc = model.evaluate(X_test, Y_test)\n",
        "print('Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tmf-iZVhyZdB",
        "outputId": "e7d33db1-e084-4fbd-a286-61366e4b0b76"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting mnist2.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%run mnist2.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69NZlbCNyryA",
        "outputId": "717f13e2-f1dc-474f-8697-29a95a597c5a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60000 train samples\n",
            "10000 test samples\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_layer_1 (Dense)       (None, 64)                50240     \n",
            "                                                                 \n",
            " dense_layer_2 (Dense)       (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_layer_3 (Dense)       (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 55,050\n",
            "Trainable params: 55,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.5767 - accuracy: 0.5627 - val_loss: 0.8543 - val_accuracy: 0.8065\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6607 - accuracy: 0.8334 - val_loss: 0.4861 - val_accuracy: 0.8742\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4656 - accuracy: 0.8753 - val_loss: 0.3891 - val_accuracy: 0.8945\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3959 - accuracy: 0.8895 - val_loss: 0.3458 - val_accuracy: 0.9042\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3591 - accuracy: 0.8997 - val_loss: 0.3190 - val_accuracy: 0.9111\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3351 - accuracy: 0.9051 - val_loss: 0.3019 - val_accuracy: 0.9151\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3177 - accuracy: 0.9102 - val_loss: 0.2883 - val_accuracy: 0.9187\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3033 - accuracy: 0.9134 - val_loss: 0.2773 - val_accuracy: 0.9230\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2912 - accuracy: 0.9173 - val_loss: 0.2673 - val_accuracy: 0.9251\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2808 - accuracy: 0.9196 - val_loss: 0.2599 - val_accuracy: 0.9270\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2714 - accuracy: 0.9217 - val_loss: 0.2527 - val_accuracy: 0.9284\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2631 - accuracy: 0.9242 - val_loss: 0.2465 - val_accuracy: 0.9295\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2552 - accuracy: 0.9268 - val_loss: 0.2401 - val_accuracy: 0.9315\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2482 - accuracy: 0.9287 - val_loss: 0.2346 - val_accuracy: 0.9327\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2413 - accuracy: 0.9307 - val_loss: 0.2298 - val_accuracy: 0.9352\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2347 - accuracy: 0.9329 - val_loss: 0.2237 - val_accuracy: 0.9359\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2291 - accuracy: 0.9348 - val_loss: 0.2190 - val_accuracy: 0.9378\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2233 - accuracy: 0.9361 - val_loss: 0.2155 - val_accuracy: 0.9382\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2179 - accuracy: 0.9375 - val_loss: 0.2117 - val_accuracy: 0.9404\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2130 - accuracy: 0.9391 - val_loss: 0.2077 - val_accuracy: 0.9419\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2075 - accuracy: 0.9407 - val_loss: 0.2042 - val_accuracy: 0.9422\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2029 - accuracy: 0.9416 - val_loss: 0.2003 - val_accuracy: 0.9419\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1982 - accuracy: 0.9433 - val_loss: 0.1959 - val_accuracy: 0.9440\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1937 - accuracy: 0.9444 - val_loss: 0.1933 - val_accuracy: 0.9455\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1896 - accuracy: 0.9456 - val_loss: 0.1901 - val_accuracy: 0.9452\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1853 - accuracy: 0.9462 - val_loss: 0.1876 - val_accuracy: 0.9457\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1813 - accuracy: 0.9478 - val_loss: 0.1837 - val_accuracy: 0.9483\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1775 - accuracy: 0.9489 - val_loss: 0.1805 - val_accuracy: 0.9492\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1736 - accuracy: 0.9505 - val_loss: 0.1774 - val_accuracy: 0.9503\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1700 - accuracy: 0.9510 - val_loss: 0.1741 - val_accuracy: 0.9508\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1666 - accuracy: 0.9523 - val_loss: 0.1727 - val_accuracy: 0.9507\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1631 - accuracy: 0.9527 - val_loss: 0.1688 - val_accuracy: 0.9519\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1598 - accuracy: 0.9542 - val_loss: 0.1667 - val_accuracy: 0.9523\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1567 - accuracy: 0.9554 - val_loss: 0.1652 - val_accuracy: 0.9522\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1538 - accuracy: 0.9561 - val_loss: 0.1616 - val_accuracy: 0.9534\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1506 - accuracy: 0.9571 - val_loss: 0.1611 - val_accuracy: 0.9542\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1479 - accuracy: 0.9576 - val_loss: 0.1583 - val_accuracy: 0.9542\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1452 - accuracy: 0.9586 - val_loss: 0.1558 - val_accuracy: 0.9548\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1423 - accuracy: 0.9594 - val_loss: 0.1537 - val_accuracy: 0.9555\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1397 - accuracy: 0.9603 - val_loss: 0.1520 - val_accuracy: 0.9559\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1372 - accuracy: 0.9611 - val_loss: 0.1500 - val_accuracy: 0.9574\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1347 - accuracy: 0.9615 - val_loss: 0.1474 - val_accuracy: 0.9576\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1325 - accuracy: 0.9622 - val_loss: 0.1458 - val_accuracy: 0.9582\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1302 - accuracy: 0.9628 - val_loss: 0.1449 - val_accuracy: 0.9584\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1278 - accuracy: 0.9637 - val_loss: 0.1432 - val_accuracy: 0.9594\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1256 - accuracy: 0.9641 - val_loss: 0.1416 - val_accuracy: 0.9603\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1236 - accuracy: 0.9649 - val_loss: 0.1401 - val_accuracy: 0.9600\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1216 - accuracy: 0.9659 - val_loss: 0.1389 - val_accuracy: 0.9609\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1196 - accuracy: 0.9659 - val_loss: 0.1377 - val_accuracy: 0.9610\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1179 - accuracy: 0.9662 - val_loss: 0.1360 - val_accuracy: 0.9620\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1323 - accuracy: 0.9594\n",
            "Test accuracy: 0.9593999981880188\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Change Model Fit Parameters\n",
        "* Change Epochs\n",
        "* Change Batch Size\n",
        "```\n",
        "# network and training\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 128\n",
        "```\n"
      ],
      "metadata": {
        "id": "NhB4NhIy0tEa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile mnist3.py\n",
        "### MNIST Ver 3\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "\n",
        "# for reproducibility\n",
        "np.random.seed(1671)\n",
        "\n",
        "# network and training\n",
        "EPOCHS = 75\n",
        "BATCH_SIZE = 128\n",
        "VERBOSE = 1\n",
        "NB_CLASSES = 10   # number of outputs = number of digits\n",
        "N_HIDDEN = 64\n",
        "VALIDATION_SPLIT=0.2 # how much TRAIN is reserved for VALIDATION\n",
        "\n",
        "# loading MNIST dataset\n",
        "# verify\n",
        "# the split between train and test is 60,000, and 10,000 respectly \n",
        "# one-hot is automatically applied\n",
        "mnist = keras.datasets.mnist\n",
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')\n",
        "\n",
        "\n",
        "#normalize in [0,1]\n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
        "#X_train is 60000 rows of 28x28 values --> reshaped in 60000 x 784\n",
        "RESHAPED = 784\n",
        "#\n",
        "X_train = X_train.reshape(60000, RESHAPED)\n",
        "X_test = X_test.reshape(10000, RESHAPED)\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "# One-hot representation of the labels.\n",
        "Y_train = tf.keras.utils.to_categorical(Y_train, NB_CLASSES) \n",
        "Y_test = tf.keras.utils.to_categorical(Y_test, NB_CLASSES)\n",
        "\n",
        "model = tf.keras.models.Sequential() \n",
        "model.add(keras.layers.Dense(N_HIDDEN,\n",
        "             input_shape=(RESHAPED,),name='dense_layer_1', activation='relu')) \n",
        "model.add(keras.layers.Dense(N_HIDDEN,name='dense_layer_2', activation='relu')) \n",
        "model.add(keras.layers.Dense(NB_CLASSES,name='dense_layer_3', activation='softmax'))\n",
        "\n",
        "# summary of the model\n",
        "model.summary()\n",
        "\n",
        "# compiling the model\n",
        "model.compile(optimizer='SGD', \n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#training the moodel\n",
        "model.fit(X_train, Y_train,\n",
        "\t\tbatch_size=BATCH_SIZE, epochs=EPOCHS,\n",
        "\t\tverbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
        "\n",
        "#evalute the model\n",
        "test_loss, test_acc = model.evaluate(X_test, Y_test)\n",
        "print('Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1636bf40-8e47-40b5-e7c1-ffdbd669bf94",
        "id": "IifJBNoz1KG8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting mnist3.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%run mnist3.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiKRb_aP1Pc_",
        "outputId": "4f6b429e-2a75-4f22-e51a-3d373327756b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60000 train samples\n",
            "10000 test samples\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_layer_1 (Dense)       (None, 64)                50240     \n",
            "                                                                 \n",
            " dense_layer_2 (Dense)       (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_layer_3 (Dense)       (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 55,050\n",
            "Trainable params: 55,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/75\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.5882 - accuracy: 0.5784 - val_loss: 0.9002 - val_accuracy: 0.7902\n",
            "Epoch 2/75\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6888 - accuracy: 0.8254 - val_loss: 0.5141 - val_accuracy: 0.8651\n",
            "Epoch 3/75\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4836 - accuracy: 0.8693 - val_loss: 0.4079 - val_accuracy: 0.8867\n",
            "Epoch 4/75\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4105 - accuracy: 0.8853 - val_loss: 0.3611 - val_accuracy: 0.8973\n",
            "Epoch 5/75\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3715 - accuracy: 0.8953 - val_loss: 0.3319 - val_accuracy: 0.9049\n",
            "Epoch 6/75\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3460 - accuracy: 0.9013 - val_loss: 0.3151 - val_accuracy: 0.9090\n",
            "Epoch 7/75\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3277 - accuracy: 0.9059 - val_loss: 0.2994 - val_accuracy: 0.9124\n",
            "Epoch 8/75\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3131 - accuracy: 0.9108 - val_loss: 0.2884 - val_accuracy: 0.9167\n",
            "Epoch 9/75\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3007 - accuracy: 0.9137 - val_loss: 0.2779 - val_accuracy: 0.9198\n",
            "Epoch 10/75\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2904 - accuracy: 0.9164 - val_loss: 0.2718 - val_accuracy: 0.9223\n",
            "Epoch 11/75\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2808 - accuracy: 0.9189 - val_loss: 0.2629 - val_accuracy: 0.9243\n",
            "Epoch 12/75\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2722 - accuracy: 0.9219 - val_loss: 0.2575 - val_accuracy: 0.9253\n",
            "Epoch 13/75\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2643 - accuracy: 0.9241 - val_loss: 0.2499 - val_accuracy: 0.9281\n",
            "Epoch 14/75\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2571 - accuracy: 0.9261 - val_loss: 0.2442 - val_accuracy: 0.9293\n",
            "Epoch 15/75\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2499 - accuracy: 0.9282 - val_loss: 0.2404 - val_accuracy: 0.9326\n",
            "Epoch 16/75\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2435 - accuracy: 0.9303 - val_loss: 0.2341 - val_accuracy: 0.9319\n",
            "Epoch 17/75\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2375 - accuracy: 0.9319 - val_loss: 0.2294 - val_accuracy: 0.9356\n",
            "Epoch 18/75\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2317 - accuracy: 0.9335 - val_loss: 0.2253 - val_accuracy: 0.9358\n",
            "Epoch 19/75\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2260 - accuracy: 0.9353 - val_loss: 0.2204 - val_accuracy: 0.9378\n",
            "Epoch 20/75\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2204 - accuracy: 0.9371 - val_loss: 0.2158 - val_accuracy: 0.9383\n",
            "Epoch 21/75\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2157 - accuracy: 0.9381 - val_loss: 0.2112 - val_accuracy: 0.9409\n",
            "Epoch 22/75\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.2108 - accuracy: 0.9400 - val_loss: 0.2076 - val_accuracy: 0.9430\n",
            "Epoch 23/75\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2059 - accuracy: 0.9413 - val_loss: 0.2036 - val_accuracy: 0.9439\n",
            "Epoch 24/75\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2014 - accuracy: 0.9431 - val_loss: 0.2005 - val_accuracy: 0.9439\n",
            "Epoch 25/75\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1972 - accuracy: 0.9441 - val_loss: 0.1980 - val_accuracy: 0.9446\n",
            "Epoch 26/75\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1929 - accuracy: 0.9451 - val_loss: 0.1932 - val_accuracy: 0.9467\n",
            "Epoch 27/75\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1888 - accuracy: 0.9462 - val_loss: 0.1907 - val_accuracy: 0.9464\n",
            "Epoch 28/75\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1850 - accuracy: 0.9474 - val_loss: 0.1872 - val_accuracy: 0.9477\n",
            "Epoch 29/75\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1813 - accuracy: 0.9485 - val_loss: 0.1843 - val_accuracy: 0.9492\n",
            "Epoch 30/75\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1775 - accuracy: 0.9490 - val_loss: 0.1816 - val_accuracy: 0.9498\n",
            "Epoch 31/75\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1739 - accuracy: 0.9503 - val_loss: 0.1787 - val_accuracy: 0.9499\n",
            "Epoch 32/75\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1708 - accuracy: 0.9511 - val_loss: 0.1762 - val_accuracy: 0.9511\n",
            "Epoch 33/75\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1674 - accuracy: 0.9521 - val_loss: 0.1741 - val_accuracy: 0.9518\n",
            "Epoch 34/75\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1641 - accuracy: 0.9528 - val_loss: 0.1718 - val_accuracy: 0.9531\n",
            "Epoch 35/75\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1612 - accuracy: 0.9536 - val_loss: 0.1696 - val_accuracy: 0.9527\n",
            "Epoch 36/75\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1582 - accuracy: 0.9547 - val_loss: 0.1672 - val_accuracy: 0.9538\n",
            "Epoch 37/75\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1555 - accuracy: 0.9554 - val_loss: 0.1647 - val_accuracy: 0.9542\n",
            "Epoch 38/75\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1526 - accuracy: 0.9564 - val_loss: 0.1625 - val_accuracy: 0.9556\n",
            "Epoch 39/75\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1499 - accuracy: 0.9570 - val_loss: 0.1606 - val_accuracy: 0.9560\n",
            "Epoch 40/75\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1473 - accuracy: 0.9586 - val_loss: 0.1593 - val_accuracy: 0.9563\n",
            "Epoch 41/75\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1447 - accuracy: 0.9588 - val_loss: 0.1579 - val_accuracy: 0.9564\n",
            "Epoch 42/75\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1422 - accuracy: 0.9596 - val_loss: 0.1565 - val_accuracy: 0.9582\n",
            "Epoch 43/75\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1400 - accuracy: 0.9603 - val_loss: 0.1536 - val_accuracy: 0.9579\n",
            "Epoch 44/75\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1377 - accuracy: 0.9609 - val_loss: 0.1522 - val_accuracy: 0.9595\n",
            "Epoch 45/75\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1353 - accuracy: 0.9613 - val_loss: 0.1507 - val_accuracy: 0.9592\n",
            "Epoch 46/75\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1332 - accuracy: 0.9617 - val_loss: 0.1496 - val_accuracy: 0.9594\n",
            "Epoch 47/75\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1312 - accuracy: 0.9625 - val_loss: 0.1475 - val_accuracy: 0.9603\n",
            "Epoch 48/75\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1289 - accuracy: 0.9635 - val_loss: 0.1456 - val_accuracy: 0.9612\n",
            "Epoch 49/75\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1270 - accuracy: 0.9635 - val_loss: 0.1443 - val_accuracy: 0.9607\n",
            "Epoch 50/75\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1249 - accuracy: 0.9643 - val_loss: 0.1438 - val_accuracy: 0.9610\n",
            "Epoch 51/75\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1230 - accuracy: 0.9649 - val_loss: 0.1417 - val_accuracy: 0.9612\n",
            "Epoch 52/75\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1211 - accuracy: 0.9650 - val_loss: 0.1408 - val_accuracy: 0.9615\n",
            "Epoch 53/75\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1192 - accuracy: 0.9661 - val_loss: 0.1394 - val_accuracy: 0.9622\n",
            "Epoch 54/75\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1173 - accuracy: 0.9661 - val_loss: 0.1385 - val_accuracy: 0.9623\n",
            "Epoch 55/75\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1157 - accuracy: 0.9670 - val_loss: 0.1373 - val_accuracy: 0.9628\n",
            "Epoch 56/75\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1140 - accuracy: 0.9676 - val_loss: 0.1382 - val_accuracy: 0.9622\n",
            "Epoch 57/75\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1126 - accuracy: 0.9676 - val_loss: 0.1339 - val_accuracy: 0.9646\n",
            "Epoch 58/75\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1107 - accuracy: 0.9683 - val_loss: 0.1337 - val_accuracy: 0.9634\n",
            "Epoch 59/75\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1094 - accuracy: 0.9690 - val_loss: 0.1321 - val_accuracy: 0.9644\n",
            "Epoch 60/75\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1076 - accuracy: 0.9692 - val_loss: 0.1311 - val_accuracy: 0.9646\n",
            "Epoch 61/75\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1063 - accuracy: 0.9698 - val_loss: 0.1299 - val_accuracy: 0.9646\n",
            "Epoch 62/75\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1048 - accuracy: 0.9700 - val_loss: 0.1304 - val_accuracy: 0.9652\n",
            "Epoch 63/75\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1033 - accuracy: 0.9704 - val_loss: 0.1290 - val_accuracy: 0.9650\n",
            "Epoch 64/75\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1020 - accuracy: 0.9711 - val_loss: 0.1277 - val_accuracy: 0.9648\n",
            "Epoch 65/75\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1006 - accuracy: 0.9717 - val_loss: 0.1268 - val_accuracy: 0.9663\n",
            "Epoch 66/75\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0991 - accuracy: 0.9718 - val_loss: 0.1268 - val_accuracy: 0.9658\n",
            "Epoch 67/75\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.0981 - accuracy: 0.9725 - val_loss: 0.1252 - val_accuracy: 0.9655\n",
            "Epoch 68/75\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0967 - accuracy: 0.9728 - val_loss: 0.1247 - val_accuracy: 0.9657\n",
            "Epoch 69/75\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.0953 - accuracy: 0.9728 - val_loss: 0.1243 - val_accuracy: 0.9653\n",
            "Epoch 70/75\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0943 - accuracy: 0.9737 - val_loss: 0.1231 - val_accuracy: 0.9663\n",
            "Epoch 71/75\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.0932 - accuracy: 0.9737 - val_loss: 0.1225 - val_accuracy: 0.9665\n",
            "Epoch 72/75\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.0921 - accuracy: 0.9741 - val_loss: 0.1215 - val_accuracy: 0.9658\n",
            "Epoch 73/75\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0908 - accuracy: 0.9744 - val_loss: 0.1206 - val_accuracy: 0.9674\n",
            "Epoch 74/75\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.0896 - accuracy: 0.9746 - val_loss: 0.1203 - val_accuracy: 0.9666\n",
            "Epoch 75/75\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.0885 - accuracy: 0.9753 - val_loss: 0.1195 - val_accuracy: 0.9678\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1103 - accuracy: 0.9664\n",
            "Test accuracy: 0.9664000272750854\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Change Optimizer\n",
        "```\n",
        "model.compile(optimizer='adam',\n",
        "                 loss='categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "dWOY6GuM12TF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile mnist4.py\n",
        "### MNIST Ver 4\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "\n",
        "# for reproducibility\n",
        "np.random.seed(1671)\n",
        "\n",
        "# network and training\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 128\n",
        "VERBOSE = 1\n",
        "NB_CLASSES = 10   # number of outputs = number of digits\n",
        "N_HIDDEN = 64\n",
        "VALIDATION_SPLIT=0.2 # how much TRAIN is reserved for VALIDATION\n",
        "\n",
        "# loading MNIST dataset\n",
        "# verify\n",
        "# the split between train and test is 60,000, and 10,000 respectly \n",
        "# one-hot is automatically applied\n",
        "mnist = keras.datasets.mnist\n",
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')\n",
        "\n",
        "\n",
        "#normalize in [0,1]\n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
        "#X_train is 60000 rows of 28x28 values --> reshaped in 60000 x 784\n",
        "RESHAPED = 784\n",
        "#\n",
        "X_train = X_train.reshape(60000, RESHAPED)\n",
        "X_test = X_test.reshape(10000, RESHAPED)\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "# One-hot representation of the labels.\n",
        "Y_train = tf.keras.utils.to_categorical(Y_train, NB_CLASSES) \n",
        "Y_test = tf.keras.utils.to_categorical(Y_test, NB_CLASSES)\n",
        "\n",
        "model = tf.keras.models.Sequential() \n",
        "model.add(keras.layers.Dense(N_HIDDEN,\n",
        "             input_shape=(RESHAPED,),name='dense_layer_1', activation='relu')) \n",
        "model.add(keras.layers.Dense(N_HIDDEN,name='dense_layer_2', activation='relu')) \n",
        "model.add(keras.layers.Dense(NB_CLASSES,name='dense_layer_3', activation='softmax'))\n",
        "\n",
        "# summary of the model\n",
        "model.summary()\n",
        "\n",
        "# compiling the model\n",
        "model.compile(optimizer='SGD', \n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#training the moodel\n",
        "model.fit(X_train, Y_train,\n",
        "\t\tbatch_size=BATCH_SIZE, epochs=EPOCHS,\n",
        "\t\tverbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
        "\n",
        "#evalute the model\n",
        "test_loss, test_acc = model.evaluate(X_test, Y_test)\n",
        "print('Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56da0cd9-9f51-4aec-f7b6-37616313a84b",
        "id": "xGSM0cIE2zbr"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting mnist4.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%run mnist4.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gvq3SBNo21jf",
        "outputId": "8f8d9c0c-7ab0-45d7-e2c1-ad68e88ca0e9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60000 train samples\n",
            "10000 test samples\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_layer_1 (Dense)       (None, 64)                50240     \n",
            "                                                                 \n",
            " dense_layer_2 (Dense)       (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_layer_3 (Dense)       (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 55,050\n",
            "Trainable params: 55,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.4740 - accuracy: 0.6432 - val_loss: 0.7296 - val_accuracy: 0.8455\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5870 - accuracy: 0.8549 - val_loss: 0.4517 - val_accuracy: 0.8825\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4397 - accuracy: 0.8794 - val_loss: 0.3776 - val_accuracy: 0.8961\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.3833 - accuracy: 0.8920 - val_loss: 0.3407 - val_accuracy: 0.9027\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3510 - accuracy: 0.9000 - val_loss: 0.3168 - val_accuracy: 0.9100\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3281 - accuracy: 0.9060 - val_loss: 0.3004 - val_accuracy: 0.9144\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3109 - accuracy: 0.9113 - val_loss: 0.2859 - val_accuracy: 0.9174\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2964 - accuracy: 0.9148 - val_loss: 0.2743 - val_accuracy: 0.9218\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2839 - accuracy: 0.9181 - val_loss: 0.2648 - val_accuracy: 0.9237\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2730 - accuracy: 0.9216 - val_loss: 0.2566 - val_accuracy: 0.9262\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2634 - accuracy: 0.9244 - val_loss: 0.2507 - val_accuracy: 0.9286\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2545 - accuracy: 0.9264 - val_loss: 0.2411 - val_accuracy: 0.9314\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2465 - accuracy: 0.9294 - val_loss: 0.2345 - val_accuracy: 0.9334\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2388 - accuracy: 0.9311 - val_loss: 0.2275 - val_accuracy: 0.9358\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2316 - accuracy: 0.9332 - val_loss: 0.2221 - val_accuracy: 0.9391\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2251 - accuracy: 0.9350 - val_loss: 0.2172 - val_accuracy: 0.9385\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2188 - accuracy: 0.9367 - val_loss: 0.2121 - val_accuracy: 0.9406\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2131 - accuracy: 0.9387 - val_loss: 0.2088 - val_accuracy: 0.9423\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2076 - accuracy: 0.9395 - val_loss: 0.2038 - val_accuracy: 0.9427\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2024 - accuracy: 0.9413 - val_loss: 0.1988 - val_accuracy: 0.9448\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1974 - accuracy: 0.9427 - val_loss: 0.1949 - val_accuracy: 0.9451\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1926 - accuracy: 0.9445 - val_loss: 0.1913 - val_accuracy: 0.9476\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1880 - accuracy: 0.9453 - val_loss: 0.1883 - val_accuracy: 0.9474\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1839 - accuracy: 0.9470 - val_loss: 0.1837 - val_accuracy: 0.9491\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1800 - accuracy: 0.9479 - val_loss: 0.1822 - val_accuracy: 0.9500\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1759 - accuracy: 0.9492 - val_loss: 0.1778 - val_accuracy: 0.9506\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1722 - accuracy: 0.9501 - val_loss: 0.1749 - val_accuracy: 0.9518\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1687 - accuracy: 0.9514 - val_loss: 0.1730 - val_accuracy: 0.9521\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1652 - accuracy: 0.9524 - val_loss: 0.1699 - val_accuracy: 0.9538\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1619 - accuracy: 0.9534 - val_loss: 0.1675 - val_accuracy: 0.9530\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1587 - accuracy: 0.9549 - val_loss: 0.1655 - val_accuracy: 0.9534\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1556 - accuracy: 0.9550 - val_loss: 0.1632 - val_accuracy: 0.9553\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1526 - accuracy: 0.9561 - val_loss: 0.1618 - val_accuracy: 0.9544\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1502 - accuracy: 0.9572 - val_loss: 0.1582 - val_accuracy: 0.9571\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1472 - accuracy: 0.9578 - val_loss: 0.1563 - val_accuracy: 0.9564\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1447 - accuracy: 0.9586 - val_loss: 0.1558 - val_accuracy: 0.9573\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1422 - accuracy: 0.9593 - val_loss: 0.1535 - val_accuracy: 0.9568\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1397 - accuracy: 0.9597 - val_loss: 0.1516 - val_accuracy: 0.9575\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1373 - accuracy: 0.9612 - val_loss: 0.1489 - val_accuracy: 0.9587\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1349 - accuracy: 0.9616 - val_loss: 0.1490 - val_accuracy: 0.9580\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1326 - accuracy: 0.9620 - val_loss: 0.1464 - val_accuracy: 0.9591\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1306 - accuracy: 0.9626 - val_loss: 0.1450 - val_accuracy: 0.9598\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1284 - accuracy: 0.9633 - val_loss: 0.1431 - val_accuracy: 0.9607\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1261 - accuracy: 0.9642 - val_loss: 0.1425 - val_accuracy: 0.9607\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1243 - accuracy: 0.9648 - val_loss: 0.1406 - val_accuracy: 0.9610\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1223 - accuracy: 0.9653 - val_loss: 0.1407 - val_accuracy: 0.9616\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1205 - accuracy: 0.9661 - val_loss: 0.1387 - val_accuracy: 0.9608\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1186 - accuracy: 0.9663 - val_loss: 0.1380 - val_accuracy: 0.9612\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1168 - accuracy: 0.9669 - val_loss: 0.1354 - val_accuracy: 0.9629\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1151 - accuracy: 0.9673 - val_loss: 0.1350 - val_accuracy: 0.9623\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1315 - accuracy: 0.9616\n",
            "Test accuracy: 0.9616000056266785\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Change Learning Rate\n",
        "\n",
        "```\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "OPTMIZER = SGD(lr=0.001)\n",
        ":\n",
        ":\n",
        ":\n",
        "# compiling the model\n",
        "model.compile(optimizer=OPTMIZER, \n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "```\n"
      ],
      "metadata": {
        "id": "S5vcTx9r3K4b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile mnist5.py\n",
        "### MNIST Ver 5\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "OPTMIZER = SGD(lr=0.001)\n",
        "# for reproducibility\n",
        "np.random.seed(1671)\n",
        "\n",
        "# network and training\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 128\n",
        "VERBOSE = 1\n",
        "NB_CLASSES = 10   # number of outputs = number of digits\n",
        "N_HIDDEN = 64\n",
        "VALIDATION_SPLIT=0.2 # how much TRAIN is reserved for VALIDATION\n",
        "\n",
        "# loading MNIST dataset\n",
        "# verify\n",
        "# the split between train and test is 60,000, and 10,000 respectly \n",
        "# one-hot is automatically applied\n",
        "mnist = keras.datasets.mnist\n",
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')\n",
        "\n",
        "\n",
        "#normalize in [0,1]\n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
        "#X_train is 60000 rows of 28x28 values --> reshaped in 60000 x 784\n",
        "RESHAPED = 784\n",
        "#\n",
        "X_train = X_train.reshape(60000, RESHAPED)\n",
        "X_test = X_test.reshape(10000, RESHAPED)\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "# One-hot representation of the labels.\n",
        "Y_train = tf.keras.utils.to_categorical(Y_train, NB_CLASSES) \n",
        "Y_test = tf.keras.utils.to_categorical(Y_test, NB_CLASSES)\n",
        "\n",
        "model = tf.keras.models.Sequential() \n",
        "model.add(keras.layers.Dense(N_HIDDEN,\n",
        "             input_shape=(RESHAPED,),name='dense_layer_1', activation='relu')) \n",
        "model.add(keras.layers.Dense(N_HIDDEN,name='dense_layer_2', activation='relu')) \n",
        "model.add(keras.layers.Dense(NB_CLASSES,name='dense_layer_3', activation='softmax'))\n",
        "\n",
        "# summary of the model\n",
        "model.summary()\n",
        "\n",
        "# compiling the model\n",
        "model.compile(optimizer=OPTMIZER, \n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#training the moodel\n",
        "model.fit(X_train, Y_train,\n",
        "\t\tbatch_size=BATCH_SIZE, epochs=EPOCHS,\n",
        "\t\tverbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
        "\n",
        "#evalute the model\n",
        "test_loss, test_acc = model.evaluate(X_test, Y_test)\n",
        "print('Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "358f4054-f04d-4ef6-9ece-c405d071bc81",
        "id": "-eVqgxnO3lY9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting mnist5.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%run mnist5.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sg2ydSEA3t0A",
        "outputId": "7766a0d8-1cb4-402f-87b3-c54a053fe4f4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60000 train samples\n",
            "10000 test samples\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_layer_1 (Dense)       (None, 64)                50240     \n",
            "                                                                 \n",
            " dense_layer_2 (Dense)       (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_layer_3 (Dense)       (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 55,050\n",
            "Trainable params: 55,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2868 - accuracy: 0.1214 - val_loss: 2.2151 - val_accuracy: 0.1903\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.1554 - accuracy: 0.2563 - val_loss: 2.0829 - val_accuracy: 0.3329\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.0153 - accuracy: 0.3735 - val_loss: 1.9242 - val_accuracy: 0.4420\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.8465 - accuracy: 0.4733 - val_loss: 1.7383 - val_accuracy: 0.5428\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.6584 - accuracy: 0.5754 - val_loss: 1.5429 - val_accuracy: 0.6376\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.4695 - accuracy: 0.6632 - val_loss: 1.3556 - val_accuracy: 0.7115\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.2952 - accuracy: 0.7211 - val_loss: 1.1893 - val_accuracy: 0.7573\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.1451 - accuracy: 0.7570 - val_loss: 1.0504 - val_accuracy: 0.7869\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.0216 - accuracy: 0.7786 - val_loss: 0.9375 - val_accuracy: 0.8052\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.9221 - accuracy: 0.7948 - val_loss: 0.8471 - val_accuracy: 0.8164\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.8423 - accuracy: 0.8069 - val_loss: 0.7747 - val_accuracy: 0.8268\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.7781 - accuracy: 0.8164 - val_loss: 0.7164 - val_accuracy: 0.8346\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7258 - accuracy: 0.8243 - val_loss: 0.6688 - val_accuracy: 0.8415\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.6826 - accuracy: 0.8316 - val_loss: 0.6296 - val_accuracy: 0.8483\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6466 - accuracy: 0.8370 - val_loss: 0.5967 - val_accuracy: 0.8533\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6161 - accuracy: 0.8426 - val_loss: 0.5689 - val_accuracy: 0.8571\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5901 - accuracy: 0.8475 - val_loss: 0.5451 - val_accuracy: 0.8627\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5676 - accuracy: 0.8514 - val_loss: 0.5245 - val_accuracy: 0.8662\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5480 - accuracy: 0.8560 - val_loss: 0.5064 - val_accuracy: 0.8689\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5306 - accuracy: 0.8593 - val_loss: 0.4908 - val_accuracy: 0.8717\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5153 - accuracy: 0.8623 - val_loss: 0.4766 - val_accuracy: 0.8739\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5015 - accuracy: 0.8656 - val_loss: 0.4641 - val_accuracy: 0.8762\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4892 - accuracy: 0.8677 - val_loss: 0.4529 - val_accuracy: 0.8790\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4780 - accuracy: 0.8701 - val_loss: 0.4428 - val_accuracy: 0.8807\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4679 - accuracy: 0.8732 - val_loss: 0.4336 - val_accuracy: 0.8827\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4586 - accuracy: 0.8746 - val_loss: 0.4251 - val_accuracy: 0.8852\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4502 - accuracy: 0.8772 - val_loss: 0.4175 - val_accuracy: 0.8867\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4423 - accuracy: 0.8784 - val_loss: 0.4106 - val_accuracy: 0.8878\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4351 - accuracy: 0.8801 - val_loss: 0.4040 - val_accuracy: 0.8897\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4284 - accuracy: 0.8813 - val_loss: 0.3982 - val_accuracy: 0.8896\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4222 - accuracy: 0.8827 - val_loss: 0.3924 - val_accuracy: 0.8917\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4164 - accuracy: 0.8842 - val_loss: 0.3871 - val_accuracy: 0.8924\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4109 - accuracy: 0.8856 - val_loss: 0.3822 - val_accuracy: 0.8936\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4058 - accuracy: 0.8864 - val_loss: 0.3777 - val_accuracy: 0.8949\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4010 - accuracy: 0.8880 - val_loss: 0.3735 - val_accuracy: 0.8948\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.3965 - accuracy: 0.8888 - val_loss: 0.3693 - val_accuracy: 0.8963\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3921 - accuracy: 0.8897 - val_loss: 0.3656 - val_accuracy: 0.8971\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.3881 - accuracy: 0.8910 - val_loss: 0.3620 - val_accuracy: 0.8973\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3842 - accuracy: 0.8919 - val_loss: 0.3584 - val_accuracy: 0.8984\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3805 - accuracy: 0.8926 - val_loss: 0.3552 - val_accuracy: 0.8997\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3770 - accuracy: 0.8937 - val_loss: 0.3521 - val_accuracy: 0.8997\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3736 - accuracy: 0.8941 - val_loss: 0.3490 - val_accuracy: 0.9003\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3705 - accuracy: 0.8949 - val_loss: 0.3462 - val_accuracy: 0.9018\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3673 - accuracy: 0.8958 - val_loss: 0.3436 - val_accuracy: 0.9024\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3645 - accuracy: 0.8964 - val_loss: 0.3410 - val_accuracy: 0.9026\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3616 - accuracy: 0.8974 - val_loss: 0.3384 - val_accuracy: 0.9038\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3589 - accuracy: 0.8976 - val_loss: 0.3360 - val_accuracy: 0.9040\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.3563 - accuracy: 0.8983 - val_loss: 0.3337 - val_accuracy: 0.9049\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.3537 - accuracy: 0.8995 - val_loss: 0.3314 - val_accuracy: 0.9053\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3513 - accuracy: 0.9000 - val_loss: 0.3295 - val_accuracy: 0.9055\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3319 - accuracy: 0.9055\n",
            "Test accuracy: 0.9054999947547913\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add Regularization\n",
        " * L1/L2\n",
        "  \n",
        "  There are three different types of regularization used in machine learning:\n",
        "  * L1 regularization (also known as LASSO): The complexity of the model is expressed as the sum of the absolute values of the weights.\n",
        "  * L2 regularization (also known as Ridge): The complexity of the model is expressed as the sum of the squares of the weights\n",
        "  * Elastic regularization: The complexity of the model is captured by a combination of the preceding two techniques\n",
        " ```\n",
        "from tf.keras.regularizers import l2, activity_l2 \n",
        "model.add(Dense(64, input_dim=64, W_regularizer=l2(0.01), activity_regularizer=activity_l2(0.01)))\n",
        " ```\n",
        "\n",
        "\n",
        "## Add Special Layers\n",
        " * Dropout Layer\n",
        "```\n",
        "model.add(keras.layers.Dropout(DROPOUT))\n",
        "```\n",
        " * Batchnormalization Layer\n",
        "```\n",
        "model.add(keras.layers.BatchNormalization()\n",
        "```\n"
      ],
      "metadata": {
        "id": "7n3ILM3Y3Vxc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "y7DjshAE5Leo"
      },
      "execution_count": 13,
      "outputs": []
    }
  ]
}